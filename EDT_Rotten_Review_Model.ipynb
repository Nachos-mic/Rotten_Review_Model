{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nachos-mic/Rotten_Review_Model/blob/main/EDT_Rotten_Review_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9psosgj3dSEM"
      },
      "source": [
        "Movie Review Analysis Pipeline\n",
        "IMDB Sentiment Model + Rotten Tomatoes Fake/Biased Review Detection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4el--2IC4y3"
      },
      "source": [
        "#Można dodać ten model jakiś gotowy co wykrywa bota albo zrobić własny\n",
        "znajdziesz to przy fake reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VaAJqGyC6IO"
      },
      "source": [
        "#Można wyselekcjonować te recenzje które mają podejrzaną ocene (nie te związane z datą) nie jestem pewien które. Może te które są podejrzanie pozytywnie lub podejrzanie negatywnie (odstają) i liczyć ich cosine similarity coś takiego"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtFGdUJP-L9S"
      },
      "source": [
        "#A tak to upewnij się że pipline od początku do końca jest czysty i ma sens. Że dane są oczyszczane i standaryzowane że te 2 datasety reviews i movies są mergowane że są tworzone te nowe cechy itp itd żeby to co już mamy było"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R7-S1__-69Y"
      },
      "source": [
        "# Dla każdego krytyka:\n",
        "- średnia ocena\n",
        "- odchylenie standardowe\n",
        "- rozkład Fresh/Rotten\n",
        "- średnia długość\n",
        "\n",
        "# Dla każdej recenzji oblicz:\n",
        "1. Z-score? odchylenia od średniej krytyka\n",
        "2. Rozbieżność: |sentiment_score - actual_rating| (to dla regresji) i zaznaczyć rozbieżność sentymentu (ale sentyment nie jakiś bardzo znaczący)\n",
        "3. Odchylenie od consensusu (tomatometer) że podjerzane jak tomatometer 80% się podoba a jemu sie nie podoba i rating dany bardzo niski (bardzo odstający) od średniego ratingu\n",
        "4. Odchylenie od średniej wydawcy (nwm czy to ma sens)\n",
        "\n",
        "# Bias score = weighted combination\n",
        "bias_score = w1*z_score + w2*sentiment_diff + w3*consensus_diff (niekoniecznie taki to przykład ale nie wiem czy ma sens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaBwOd3IAO_2"
      },
      "source": [
        "#Znalezione rodzaje unreliable/biased recenzji\n",
        "\n",
        "1. Recenzje wstawione batchowo przede wszystkim stare\n",
        "2. Recenzje z anomalią ocenową\n",
        "3. weź to tak wypisz co jest w notatniku i sprawdz z perplxem co można jeszcze uwzględnić ale jak już wypiszesz i ew coś wymyślisz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN3S_q62A3D7"
      },
      "source": [
        "Ja siędze nad umwdm i nad zmumem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwZ7_dj3e_Go"
      },
      "source": [
        "#TRENING MODELU 1 - IMDB SENTYMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7_Iwr8_drHL"
      },
      "outputs": [],
      "source": [
        "!pip install contractions -qq\n",
        "!pip install vaderSentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZYYEpyqdUmU"
      },
      "outputs": [],
      "source": [
        "# Ustawianie środowiska\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "from datetime import timedelta\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import umap.umap_ as umap\n",
        "import warnings\n",
        "\n",
        "import contractions\n",
        "from bs4 import BeautifulSoup\n",
        "import kagglehub\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Instalowanie pakietów NLTK\n",
        "for resource in ['punkt', 'stopwords', 'wordnet', 'punkt_tab', 'averaged_perceptron_tagger', 'averaged_perceptron_tagger_eng']:\n",
        "    nltk.download(resource, quiet=True)\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qB882rInQEEX"
      },
      "outputs": [],
      "source": [
        "# Funkcje do czyszczenia datasetu\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_html_tags(text):\n",
        "    soup = BeautifulSoup(text, 'html.parser')\n",
        "    return soup.get_text()\n",
        "\n",
        "def expand_contractions(text):\n",
        "    return contractions.fix(text)\n",
        "\n",
        "def to_lowercase(text):\n",
        "    return text.lower()\n",
        "\n",
        "def remove_special_characters(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
        "    return text\n",
        "\n",
        "def remove_extra_spaces(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "def remove_stopwords_and_lemmatize(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [\n",
        "        lemmatizer.lemmatize(token)\n",
        "        for token in tokens\n",
        "        if token not in stop_words and len(token) > 2\n",
        "    ]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "def clean_text(text):\n",
        "    # Obsługa NaN, None i pustych wartości\n",
        "    if pd.isna(text) or not isinstance(text, str) or not text.strip():\n",
        "        return ''\n",
        "\n",
        "    text = remove_html_tags(text)\n",
        "    text = expand_contractions(text)\n",
        "    text = to_lowercase(text)\n",
        "    text = remove_special_characters(text)\n",
        "    text = remove_extra_spaces(text)\n",
        "    text = remove_stopwords_and_lemmatize(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1XpC2EVPqO-"
      },
      "outputs": [],
      "source": [
        "#Przygotowanie datasetu\n",
        "print(\"=\"*60)\n",
        "print(\"\\nŁadowanie datasetu IMDB...\")\n",
        "\n",
        "\n",
        "dataset_path_imdb = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
        "csv_path_imdb = os.path.join(dataset_path_imdb, \"IMDB Dataset.csv\")\n",
        "df_imdb = pd.read_csv(csv_path_imdb)\n",
        "\n",
        "print(f\"Załadowano recenzje IMDB reviews\")\n",
        "print(f\"Podział sentymentu:\\n{df_imdb['sentiment'].value_counts()}\")\n",
        "\n",
        "# Przygotowanie datasetu\n",
        "print(\"\\nCzyszczenie datasetu...\")\n",
        "df_imdb['review_cleaned'] = df_imdb['review'].apply(clean_text)\n",
        "df_imdb['sentiment_label'] = df_imdb['sentiment'].map({'positive': 1, 'negative': -1})\n",
        "\n",
        "df_imdb = df_imdb[df_imdb['review_cleaned'].str.strip() != ''].copy()\n",
        "\n",
        "df_imdb_final = df_imdb[['review_cleaned', 'sentiment_label']].copy()\n",
        "df_imdb_final = df_imdb_final.rename(columns={'review_cleaned': 'text', 'sentiment_label': 'label'})\n",
        "df_imdb_final['source'] = 'IMDB'\n",
        "\n",
        "print(f\"\\nPrzygotowano dane: {df_imdb_final.shape}\")\n",
        "print(f\"Podział etykiet:\")\n",
        "print(df_imdb_final['label'].value_counts())\n",
        "print(f\"Pozytywne (1): {(df_imdb_final['label'] == 1).sum()} ({(df_imdb_final['label'] == 1).sum()/len(df_imdb_final)*100:.1f}%)\")\n",
        "print(f\"Negatywne (-1): {(df_imdb_final['label'] == -1).sum()} ({(df_imdb_final['label'] == -1).sum()/len(df_imdb_final)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x350jnY9PtOW"
      },
      "outputs": [],
      "source": [
        "# Ładowanie datasetu Rotten Tomatoes\n",
        "print(\"Ładowanie datasetu Clapper Rotten Tomatoes\")\n",
        "\n",
        "dataset_path_clapper = kagglehub.dataset_download(\n",
        "    \"andrezaza/clapper-massive-rotten-tomatoes-movies-and-reviews\"\n",
        ")\n",
        "\n",
        "csv_files = glob.glob(os.path.join(dataset_path_clapper, \"*.csv\"))\n",
        "print(f\"Znaleziono pliki: {[os.path.basename(f) for f in csv_files]}\")\n",
        "\n",
        "reviews_file = None\n",
        "for f in csv_files:\n",
        "    fname = os.path.basename(f).lower()\n",
        "    if 'review' in fname and 'movie' not in fname:\n",
        "        reviews_file = f\n",
        "        break\n",
        "    elif 'movie_review' in fname:\n",
        "        reviews_file = f\n",
        "        break\n",
        "\n",
        "if not reviews_file and csv_files:\n",
        "    for f in csv_files:\n",
        "        if 'review' in os.path.basename(f).lower():\n",
        "            reviews_file = f\n",
        "            break\n",
        "    if not reviews_file:\n",
        "        reviews_file = csv_files[0]\n",
        "\n",
        "df_clapper = pd.read_csv(reviews_file)\n",
        "\n",
        "# Filtracja top-krytyków\n",
        "top_critic_col = None\n",
        "for col in df_clapper.columns:\n",
        "    col_lower = col.lower().replace('_', '').replace(' ', '')\n",
        "    if 'topcritic' in col_lower or 'istopdcritic' in col_lower:\n",
        "        top_critic_col = col\n",
        "        break\n",
        "\n",
        "if top_critic_col:\n",
        "    print(f\"\\nFiltracja top-krytyków (przed: {len(df_clapper)})\")\n",
        "    df_clapper = df_clapper[\n",
        "        (df_clapper[top_critic_col] == True) |\n",
        "        (df_clapper[top_critic_col] == 1) |\n",
        "        (df_clapper[top_critic_col] == 'True') |\n",
        "        (df_clapper[top_critic_col] == 'true')\n",
        "    ].copy()\n",
        "    print(f\"   Po filtracji: {len(df_clapper)}\")\n",
        "else:\n",
        "    print(\"\\nKolumna top-krytyków nie znaleziona - używam wszystkich recenzji\")\n",
        "\n",
        "# Detekcja kolumn\n",
        "text_col = None\n",
        "label_col = None\n",
        "score_sentiment_col = None\n",
        "\n",
        "for col in df_clapper.columns:\n",
        "    col_lower = col.lower().replace('_', '').replace(' ', '')\n",
        "\n",
        "    if any(x in col_lower for x in ['reviewtext', 'text', 'content']):\n",
        "        if text_col is None:\n",
        "            text_col = col\n",
        "\n",
        "    if any(x in col_lower for x in ['reviewstate', 'state', 'type']):\n",
        "        if 'score' not in col_lower:\n",
        "            label_col = col\n",
        "\n",
        "    if 'scoresentiment' in col_lower or ('score' in col_lower and 'sentiment' in col_lower):\n",
        "        score_sentiment_col = col\n",
        "\n",
        "if score_sentiment_col:\n",
        "    df_clapper = df_clapper.drop(columns=[score_sentiment_col])\n",
        "\n",
        "if text_col is None or label_col is None:\n",
        "    raise ValueError(\"Nie znaleziono wymaganych kolumn text/label\")\n",
        "\n",
        "# Czyszczenie tekstu\n",
        "print(f\"\\nCzyszczenie tekstu (przed: {len(df_clapper)})\")\n",
        "df_clapper = df_clapper[df_clapper[text_col].notna()].copy()\n",
        "df_clapper['text_cleaned'] = df_clapper[text_col].apply(clean_text)\n",
        "df_clapper = df_clapper[df_clapper['text_cleaned'].str.strip() != ''].copy()\n",
        "print(f\"   Po czyszczeniu: {len(df_clapper)}\")\n",
        "\n",
        "# Mapowanie etykiet\n",
        "def map_rt_sentiment(val):\n",
        "    if pd.isna(val):\n",
        "        return None\n",
        "    val_str = str(val).lower().strip()\n",
        "    if val_str in ['fresh', 'positive', '1', 'pos']:\n",
        "        return 1\n",
        "    elif val_str in ['rotten', 'negative', '0', 'neg']:\n",
        "        return -1\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "df_clapper['sentiment_label'] = df_clapper[label_col].apply(map_rt_sentiment)\n",
        "df_clapper = df_clapper.dropna(subset=['sentiment_label']).copy()\n",
        "\n",
        "# Finalne przygotowanie\n",
        "df_clapper_final = df_clapper[['text_cleaned', 'sentiment_label']].copy()\n",
        "df_clapper_final = df_clapper_final.rename(columns={'text_cleaned': 'text', 'sentiment_label': 'label'})\n",
        "df_clapper_final['label'] = df_clapper_final['label'].astype(int)\n",
        "df_clapper_final['source'] = 'Clapper_RT'\n",
        "\n",
        "print(f\"\\nClapper RT przygotowany: {df_clapper_final.shape}\")\n",
        "print(f\"   Podział etykiet: {df_clapper_final['label'].value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXo8fS8ePwP3"
      },
      "outputs": [],
      "source": [
        "#Łączenie datasetu IMDB i Rotten\n",
        "print(\"Łączenie datasetu\")\n",
        "\n",
        "# Połącz oba datasety\n",
        "df_combined = pd.concat([df_imdb_final, df_clapper_final], ignore_index=True)\n",
        "\n",
        "# Usuń duplikaty tekstowe\n",
        "print(f\"\\nUsuwanie duplikatów...\")\n",
        "original_size = len(df_combined)\n",
        "df_combined = df_combined.drop_duplicates(subset=['text'], keep='first')\n",
        "duplicates_removed = original_size - len(df_combined)\n",
        "print(f\"Usunięto {duplicates_removed} duplikatów ({duplicates_removed/original_size*100:.1f}%)\")\n",
        "\n",
        "# Losowe przemieszanie\n",
        "df_combined = df_combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nPołączony dataset: {df_combined.shape}\")\n",
        "print(\"\\nPodział datasetu:\")\n",
        "print(f\"  IMDB: {(df_combined['source'] == 'IMDB').sum()}\")\n",
        "print(f\"  Clapper RT: {(df_combined['source'] == 'Clapper_RT').sum()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAUceU3-P0Ge"
      },
      "outputs": [],
      "source": [
        "#Trening datasetu\n",
        "print(\"Trening modelu\")\n",
        "\n",
        "print(\"\\nWektoryzacja tekstu...\")\n",
        "vectorizer = CountVectorizer(max_features=10000, ngram_range=(1, 2), min_df=2)\n",
        "X = vectorizer.fit_transform(df_combined['text'])\n",
        "y = df_combined['label']\n",
        "\n",
        "# Podział na zbiory train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nStatystyki podziału na zbiory:\")\n",
        "print(f\"   Treningowy: {X_train.shape[0]}\")\n",
        "print(f\"   Testowy: {X_test.shape[0]}\")\n",
        "print(f\"   Podział etykiet: {pd.Series(y_train).value_counts().to_dict()}\")\n",
        "\n",
        "# Trenowanie\n",
        "model = LogisticRegression(max_iter=1000, random_state=42, C=1.0)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Ewaluacja\n",
        "print(\"\\nEwaluacja modelu...\")\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "train_acc = accuracy_score(y_train, y_pred_train)\n",
        "test_acc = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "print(f\"   Train Accuracy: {train_acc:.4f}\")\n",
        "print(f\"   Test Accuracy:  {test_acc:.4f}\")\n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred_test,\n",
        "                          target_names=['Negative (-1)', 'Positive (1)']))\n",
        "\n",
        "#Macierz pomyłek\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Negative', 'Positive'],\n",
        "            yticklabels=['Negative', 'Positive'])\n",
        "plt.title('Confusion Matrix',\n",
        "          fontsize=14, fontweight='bold')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43ljQOhv7gYk"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(review_text):\n",
        "    \"\"\"Funkcja do predykcji sentymentu (pozytywne 1, negatywne -1)\"\"\"\n",
        "    cleaned = clean_text(review_text)\n",
        "    vector = vectorizer.transform([cleaned])\n",
        "    return model.predict(vector)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j76V25ffLOo"
      },
      "source": [
        "# MODEL 2 - BIAS ROTTEN TOMATOES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEmpJV6jfTL9"
      },
      "source": [
        "EDA & PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c8D4zq5e9wB"
      },
      "outputs": [],
      "source": [
        "print(\"Ładowanie datasetu Rotten Tomatoes\")\n",
        "\n",
        "dataset_path_rt = kagglehub.dataset_download(\n",
        "    \"stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset\"\n",
        ")\n",
        "\n",
        "movies_csv = os.path.join(dataset_path_rt, \"rotten_tomatoes_movies.csv\")\n",
        "reviews_csv = os.path.join(dataset_path_rt, \"rotten_tomatoes_critic_reviews.csv\")\n",
        "\n",
        "movies_df = pd.read_csv(movies_csv)\n",
        "reviews_df = pd.read_csv(reviews_csv)\n",
        "\n",
        "print(f\"\\nFilmy: {movies_df.shape}\")\n",
        "print(f\"\\nRecenzje: {reviews_df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhKVQvMSfssp"
      },
      "outputs": [],
      "source": [
        "# Analiza rozkładu sentymentu\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "if 'tomatometer_status' in movies_df.columns:\n",
        "    movies_df['tomatometer_status'].value_counts().plot(kind='bar', ax=axes[0], color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
        "    axes[0].set_title('Movies: Tomatometer Status Distribution', fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xlabel('Status')\n",
        "    axes[0].set_ylabel('Count')\n",
        "\n",
        "if 'review_type' in reviews_df.columns:\n",
        "    reviews_df['review_type'].value_counts().plot(kind='bar', ax=axes[1], color=['#00EA6E', '#FF3B3F'])\n",
        "    axes[1].set_title('Reviews: Review Type Distribution', fontsize=14, fontweight='bold')\n",
        "    axes[1].set_xlabel('Review Type')\n",
        "    axes[1].set_ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtRIYuR0fuqY"
      },
      "outputs": [],
      "source": [
        "reviews_df['review_score'].dropna().unique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbXmplkRfbSb"
      },
      "outputs": [],
      "source": [
        "# EDA 1: Początkowa eksploracja danych\n",
        "print(\"Eksploracja datasetów\")\n",
        "\n",
        "print(\"\\nRecenzje:\")\n",
        "print(f\"  Ilość recenzji: {len(reviews_df)}\")\n",
        "print(f\"  Brakujące dane:\\n{reviews_df.isnull().sum()[reviews_df.isnull().sum() > 0]}\")\n",
        "print(f\"\\n  Podział recenzentów:\")\n",
        "print(reviews_df['top_critic'].value_counts(dropna=False))\n",
        "\n",
        "print(\"\\nFilmy:\")\n",
        "print(f\"  Ilość filmów: {len(movies_df)}\")\n",
        "#Konwersja  danych z kolumny 'original_release_date' do typu datetime\n",
        "movies_df['original_release_date'] = pd.to_datetime(movies_df['original_release_date'], errors='coerce')\n",
        "print(f\"  Zakres dat: {movies_df['original_release_date'].min()} - {movies_df['original_release_date'].max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-QZspBnfymz"
      },
      "outputs": [],
      "source": [
        "#Preprocessing danych\n",
        "print(\"Filtrowanie top-krytyków\")\n",
        "\n",
        "original_count = len(reviews_df)\n",
        "reviews_df = reviews_df[reviews_df['top_critic'] == True].copy()\n",
        "print(f\"Po filtracji zostało {len(reviews_df)/original_count*100:.1f}% danych\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5qCJlszf49Q"
      },
      "outputs": [],
      "source": [
        "reviews_df['review_score'].dropna().unique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGdFNjPyf-V7"
      },
      "outputs": [],
      "source": [
        "#Łączenie datasetów\n",
        "print(\"Łączenie datasetów (Recenzje krytyków + filmy)\")\n",
        "\n",
        "movie_cols = ['rotten_tomatoes_link', 'original_release_date', 'tomatometer_rating',\n",
        "              'tomatometer_status', 'audience_rating', 'audience_status', 'movie_title']\n",
        "movies_subset = movies_df[movie_cols].copy()\n",
        "\n",
        "df = reviews_df.merge(movies_subset, on='rotten_tomatoes_link', how='left')\n",
        "print(f\"Ukończono łączenie datasetów: {df.shape}\")\n",
        "# print(f\"{(1 - df['original_release_date'].isna().sum()/len(df))*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwGO9IrDRGyt"
      },
      "outputs": [],
      "source": [
        "df['review_date'] = pd.to_datetime(df['review_date'])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.hist(\n",
        "    df['review_date'],\n",
        "    bins=50,\n",
        "    density=True\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Review Date\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.title(\"Distribution of Review Publication Dates\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNiYPKGqf_XW"
      },
      "outputs": [],
      "source": [
        "# Analiza jakości tekstów recenzji\n",
        "print(\"\\nAnaliza tekstu\")\n",
        "\n",
        "sample_reviews = df['review_content'].dropna().head(10)\n",
        "print(f\"   Przykład (pierwsze 200 znaków): {sample_reviews.iloc[0][:200]}\")\n",
        "\n",
        "html_pattern = re.compile('<.*?>')\n",
        "has_html = df['review_content'].str.contains(html_pattern, na=False).sum()\n",
        "print(f\"   Recenzje z HTML: {has_html}\")\n",
        "\n",
        "url_pattern = re.compile(r'https?://\\\\S+|www\\\\.\\\\S+')\n",
        "has_urls = df['review_content'].str.contains(url_pattern, na=False).sum()\n",
        "print(f\"   Recenzje z URL: {has_urls}\")\n",
        "\n",
        "df['review_length_raw'] = df['review_content'].str.len()\n",
        "print(f\"\\n   Statystyki długości:\")\n",
        "print(f\"      Średnia: {df['review_length_raw'].mean():.0f}\")\n",
        "print(f\"      Mediana: {df['review_length_raw'].median():.0f}\")\n",
        "print(f\"      Min-Max: {df['review_length_raw'].min():.0f} - {df['review_length_raw'].max():.0f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvwdMl-af_mN"
      },
      "outputs": [],
      "source": [
        "#Czyszczenie tekstu\n",
        "print(\"Czyszczenie tekstu\")\n",
        "\n",
        "CHAT_WORDS = {\n",
        "    \"AFAIK\": \"As Far As I Know\",\n",
        "    \"AFK\": \"Away From Keyboard\",\n",
        "    \"ASAP\": \"As Soon As Possible\",\n",
        "    \"ATK\": \"At The Keyboard\",\n",
        "    \"ATM\": \"At The Moment\",\n",
        "    \"A3\": \"Anytime, Anywhere, Anyplace\",\n",
        "    \"BAK\": \"Back At Keyboard\",\n",
        "    \"BBL\": \"Be Back Later\",\n",
        "    \"BBS\": \"Be Back Soon\",\n",
        "    \"BFN\": \"Bye For Now\",\n",
        "    \"B4N\": \"Bye For Now\",\n",
        "    \"BRB\": \"Be Right Back\",\n",
        "    \"BRT\": \"Be Right There\",\n",
        "    \"BTW\": \"By The Way\",\n",
        "    \"B4\": \"Before\",\n",
        "    \"B4N\": \"Bye For Now\",\n",
        "    \"CU\": \"See You\",\n",
        "    \"CUL8R\": \"See You Later\",\n",
        "    \"CYA\": \"See You\",\n",
        "    \"FAQ\": \"Frequently Asked Questions\",\n",
        "    \"FC\": \"Fingers Crossed\",\n",
        "    \"FWIW\": \"For What It's Worth\",\n",
        "    \"FYI\": \"For Your Information\",\n",
        "    \"GAL\": \"Get A Life\",\n",
        "    \"GG\": \"Good Game\",\n",
        "    \"GN\": \"Good Night\",\n",
        "    \"GMTA\": \"Great Minds Think Alike\",\n",
        "    \"GR8\": \"Great!\",\n",
        "    \"G9\": \"Genius\",\n",
        "    \"IC\": \"I See\",\n",
        "    \"ICQ\": \"I Seek you (also a chat program)\",\n",
        "    \"ILU\": \"ILU: I Love You\",\n",
        "    \"IMHO\": \"In My Honest/Humble Opinion\",\n",
        "    \"IMO\": \"In My Opinion\",\n",
        "    \"IOW\": \"In Other Words\",\n",
        "    \"IRL\": \"In Real Life\",\n",
        "    \"KISS\": \"Keep It Simple, Stupid\",\n",
        "    \"LDR\": \"Long Distance Relationship\",\n",
        "    \"LMAO\": \"Laugh My A.. Off\",\n",
        "    \"LOL\": \"Laughing Out Loud\",\n",
        "    \"LTNS\": \"Long Time No See\",\n",
        "    \"L8R\": \"Later\",\n",
        "    \"MTE\": \"My Thoughts Exactly\",\n",
        "    \"M8\": \"Mate\",\n",
        "    \"NRN\": \"No Reply Necessary\",\n",
        "    \"OIC\": \"Oh I See\",\n",
        "    \"PITA\": \"Pain In The A..\",\n",
        "    \"PRT\": \"Party\",\n",
        "    \"PRW\": \"Parents Are Watching\",\n",
        "    \"QPSA?\": \"Que Pasa?\",\n",
        "    \"ROFL\": \"Rolling On The Floor Laughing\",\n",
        "    \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n",
        "    \"ROTFLMAO\": \"Rolling On The Floor Laughing My A.. Off\",\n",
        "    \"SK8\": \"Skate\",\n",
        "    \"STATS\": \"Your sex and age\",\n",
        "    \"ASL\": \"Age, Sex, Location\",\n",
        "    \"THX\": \"Thank You\",\n",
        "    \"TTFN\": \"Ta-Ta For Now!\",\n",
        "    \"TTYL\": \"Talk To You Later\",\n",
        "    \"U\": \"You\",\n",
        "    \"U2\": \"You Too\",\n",
        "    \"U4E\": \"Yours For Ever\",\n",
        "    \"WB\": \"Welcome Back\",\n",
        "    \"WTF\": \"What The F...\",\n",
        "    \"WTG\": \"Way To Go!\",\n",
        "    \"WUF\": \"Where Are You From?\",\n",
        "    \"W8\": \"Wait...\",\n",
        "    \"7K\": \"Sick:-D Laugher\",\n",
        "    \"TFW\": \"That feeling when\",\n",
        "    \"MFW\": \"My face when\",\n",
        "    \"MRW\": \"My reaction when\",\n",
        "    \"IFYP\": \"I feel your pain\",\n",
        "    \"TNTL\": \"Trying not to laugh\",\n",
        "    \"JK\": \"Just kidding\",\n",
        "    \"IDC\": \"I don't care\",\n",
        "    \"ILY\": \"I love you\",\n",
        "    \"IMU\": \"I miss you\",\n",
        "    \"ADIH\": \"Another day in hell\",\n",
        "    \"ZZZ\": \"Sleeping, bored, tired\",\n",
        "    \"WYWH\": \"Wish you were here\",\n",
        "    \"TIME\": \"Tears in my eyes\",\n",
        "    \"BAE\": \"Before anyone else\",\n",
        "    \"FIMH\": \"Forever in my heart\",\n",
        "    \"BSAAW\": \"Big smile and a wink\",\n",
        "    \"BWL\": \"Bursting with laughter\",\n",
        "    \"BFF\": \"Best friends forever\",\n",
        "    \"CSL\": \"Can't stop laughing\"\n",
        "}\n",
        "\n",
        "def remove_urls(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    return re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "\n",
        "def remove_emoji(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emotikony\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbole i piktogramy\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport i symbole map\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flagi (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chińskie znaki/symbole\n",
        "        u\"\\U00002702-\\U000027B0\"  # dingbats\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001F926-\\U0001F937\"  # dodatkowe twarze i gesty\n",
        "        u\"\\U00010000-\\U0010ffff\"  # dodatkowe symbole\n",
        "        u\"\\U0001F900-\\U0001F9FF\"  # symbole emotikony (2017+)\n",
        "        u\"\\U0001FA00-\\U0001FA6F\"  # symbole rozszerzone-A\n",
        "        u\"\\U0001FA70-\\U0001FAFF\"  # symbole rozszerzone-B\n",
        "        u\"\\u2640-\\u2642\"           # symbole płci\n",
        "        u\"\\u2600-\\u2B55\"           # różne symbole\n",
        "        u\"\\u200d\"                  # zero width joiner\n",
        "        u\"\\ufe0f\"                  # variation selector\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\u3030\"\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub('', text)\n",
        "\n",
        "\n",
        "def expand_chat_words(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    words = text.split()\n",
        "    expanded = [CHAT_WORDS.get(word.upper(), word) for word in words]\n",
        "    return ' '.join(expanded)\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "def clean_text_rt(text):\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return ''\n",
        "\n",
        "    text = remove_html_tags(text)\n",
        "    text = remove_urls(text)\n",
        "    text = remove_emoji(text)\n",
        "    text = expand_chat_words(text)\n",
        "    text = text.lower()\n",
        "    text = remove_punctuation(text)\n",
        "    text = remove_extra_spaces(text)\n",
        "\n",
        "    return text\n",
        "\n",
        "print(\"Czyszczenie tekstu w recenzjach...\")\n",
        "df['text_cleaned'] = df['review_content'].apply(clean_text_rt)\n",
        "\n",
        "print(f\"Wyczyszczono {len(df)} recenzji\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKL6WGnigYeu"
      },
      "outputs": [],
      "source": [
        "# EDA 3: Analiza po czyszczeniu\n",
        "print(\"Analiza po czyszczeniu\")\n",
        "\n",
        "df['text_length_cleaned'] = df['text_cleaned'].str.len()\n",
        "print(\"Analiza długości tekstów:\")\n",
        "print(df['text_length_cleaned'].describe())\n",
        "\n",
        "print(\"\\nPrzykładowa recenzja:\")\n",
        "print(df['text_cleaned'].iloc[0][:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MHA-JjPgbWC"
      },
      "outputs": [],
      "source": [
        "#Tokenizacja i lematyzacja\n",
        "print(\"\\nTokenizacja i lematyzacja\")\n",
        "\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    tag_dict = {\n",
        "        'J': wordnet.ADJ,\n",
        "        'V': wordnet.VERB,\n",
        "        'N': wordnet.NOUN,\n",
        "        'R': wordnet.ADV\n",
        "    }\n",
        "    return tag_dict.get(treebank_tag[0], wordnet.NOUN)\n",
        "\n",
        "def tokenize_and_lemmatize(text, remove_stopwords=True, min_word_length=2):\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return []\n",
        "\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word.isalpha() and len(word) >= min_word_length]\n",
        "\n",
        "    if remove_stopwords:\n",
        "        stop_words_set = set(stopwords.words('english'))\n",
        "        custom_stopwords = {'film', 'movie', 'movies', 'films', 'scene', 'scenes'}\n",
        "        stop_words_set.update(custom_stopwords)\n",
        "        tokens = [word for word in tokens if word not in stop_words_set]\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    lemmatized = [lemmatizer.lemmatize(word, get_wordnet_pos(pos))\n",
        "                  for word, pos in pos_tags]\n",
        "\n",
        "    return lemmatized\n",
        "\n",
        "df['tokens'] = df['text_cleaned'].apply(tokenize_and_lemmatize)\n",
        "df['token_count'] = df['tokens'].apply(len)\n",
        "df['tokens_text'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "print(f\"   Średnia tokenów: {df['token_count'].mean():.1f}\")\n",
        "print(f\"   Mediana: {df['token_count'].median():.0f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWxaZzHHgdq8"
      },
      "outputs": [],
      "source": [
        "# Przetwarzanie dat\n",
        "print(\"\\nPrzetwarzanie dat\")\n",
        "\n",
        "df['review_date'] = pd.to_datetime(df['review_date'], errors='coerce')\n",
        "df['original_release_date'] = pd.to_datetime(df['original_release_date'], errors='coerce')\n",
        "\n",
        "df['review_year'] = df['review_date'].dt.year\n",
        "df['review_month'] = df['review_date'].dt.month\n",
        "df['release_year'] = df['original_release_date'].dt.year\n",
        "\n",
        "df['days_since_release'] = (df['review_date'] - df['original_release_date']).dt.days\n",
        "\n",
        "print(f\"   Recenzje z datami: {df['days_since_release'].notna().sum()}\")\n",
        "print(f\"   Zakres: {df['review_date'].min()} - {df['review_date'].max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtO2MNOggjt8"
      },
      "outputs": [],
      "source": [
        "# Analiza czasowa recenzji\n",
        "print(\"\\nAnaliza czasowa recenzji\")\n",
        "\n",
        "early_reviews = (df['days_since_release'] < 7).sum()\n",
        "print(f\"   Wczesne recenzje (< 7 dni): {early_reviews} ({early_reviews/len(df)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\n   Dni od premiery:\")\n",
        "print(f\"      Średnia: {df['days_since_release'].mean():.0f}\")\n",
        "print(f\"      Mediana: {df['days_since_release'].median():.0f}\")\n",
        "print(f\"      Min-Max: {df['days_since_release'].min():.0f} - {df['days_since_release'].max():.0f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqqkOKKMPbaI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "df['days_since_release'].plot.hist(\n",
        "    bins=60,\n",
        "    density=True\n",
        ")\n",
        "\n",
        "plt.axvline(0)\n",
        "plt.xlabel(\"Days Since Release\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.title(\"Review Timing Distribution (Normalized)\")\n",
        "\n",
        "plt.xlim(-60, 180)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziXqhJPhPFXX"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "df[\n",
        "    (df['days_since_release'] >= -400) &\n",
        "    (df['days_since_release'] <= 14)\n",
        "]['days_since_release'].plot.hist(\n",
        "    bins=28,\n",
        "    density=True\n",
        ")\n",
        "\n",
        "plt.axvline(0)\n",
        "plt.xlabel(\"Days Since Release\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.title(\"Review Distribution Around Release (±14 Days)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jkTtVgiP-_V"
      },
      "outputs": [],
      "source": [
        "df.sort_values('days_since_release').head(5)[\n",
        "    ['movie_title', 'days_since_release', 'review_date', 'original_release_date']\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnnO5wvfR5Aq"
      },
      "outputs": [],
      "source": [
        "# upewnij się, że daty są datetime\n",
        "df['review_date'] = pd.to_datetime(df['review_date'])\n",
        "df['original_release_date'] = pd.to_datetime(df['original_release_date'])\n",
        "\n",
        "# znajdź najnowszy film (max release_date)\n",
        "latest_release_date = df['original_release_date'].max()\n",
        "\n",
        "# wszystkie recenzje tego filmu\n",
        "latest_movie_reviews = df[df['original_release_date'] == latest_release_date]\n",
        "\n",
        "# najstarsza recenzja dla tego filmu\n",
        "oldest_review_latest_movie = latest_movie_reviews.sort_values('review_date').head(1)\n",
        "\n",
        "oldest_review_latest_movie[\n",
        "    ['movie_title', 'original_release_date', 'review_date', 'days_since_release']\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XaDGKKKg0Vw"
      },
      "outputs": [],
      "source": [
        "# Feature engineering\n",
        "print(\"\\nFeature engineering\")\n",
        "\n",
        "df['review_type_encoded'] = df['review_type'].map({'Fresh': 1, 'Rotten': 0})\n",
        "\n",
        "df['word_count'] = df['text_cleaned'].str.split().str.len()\n",
        "df['sentence_count'] = df['text_cleaned'].str.count(r'[.!?]') + 1\n",
        "df['avg_word_length'] = df['text_length_cleaned'] / df['word_count'].replace(0, 1)\n",
        "df['unique_word_count'] = df['tokens'].apply(lambda x: len(set(x)))\n",
        "df['lexical_diversity'] = df['unique_word_count'] / df['token_count'].replace(0, 1)\n",
        "\n",
        "df['is_early_review'] = df['days_since_release'] < 7\n",
        "\n",
        "print(f\"   Utworzono cechy: tekstowe (7), czasowe (5), kategoryczne (1)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-kE0F4sg3qx"
      },
      "outputs": [],
      "source": [
        "#Dodanie sentymentu z modelu nr.1\n",
        "print(\"\\nPredykcja sentymentu\")\n",
        "\n",
        "df['predicted_sentiment'] = df['text_cleaned'].apply(predict_sentiment)\n",
        "\n",
        "sentiment_dist = df['predicted_sentiment'].value_counts()\n",
        "print(f\"   Pozytywny (1): {sentiment_dist.get(1, 0)} ({sentiment_dist.get(1, 0)/len(df)*100:.1f}%)\")\n",
        "print(f\"   Negatywny (-1): {sentiment_dist.get(-1, 0)} ({sentiment_dist.get(-1, 0)/len(df)*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgoWD3Eqg_MA"
      },
      "outputs": [],
      "source": [
        "# EDA 5: Walidacja modelu sentymentu\n",
        "print(\"\\nWalidacja modelu sentymentu\")\n",
        "\n",
        "crosstab = pd.crosstab(\n",
        "    df['review_type'],\n",
        "    df['predicted_sentiment'],\n",
        "    normalize='index'\n",
        ") * 100\n",
        "\n",
        "print(f\"\\n   Predykcja sentymentu wg typu recenzji (%):\")\n",
        "print(crosstab.round(1).to_string(index=True).replace('\\n', '\\n   '))\n",
        "\n",
        "df['sentiment_matches'] = (\n",
        "    ((df['review_type'] == 'Fresh') & (df['predicted_sentiment'] == 1)) |\n",
        "    ((df['review_type'] == 'Rotten') & (df['predicted_sentiment'] == -1))\n",
        ")\n",
        "agreement = df['sentiment_matches'].mean() * 100\n",
        "print(f\"\\n   Zgodność: {agreement:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgOz0DQhhBs3"
      },
      "outputs": [],
      "source": [
        "# Generowanie chmur słów\n",
        "print(\"\\nGenerowanie chmur słów\")\n",
        "\n",
        "def generate_wordcloud(tokens_series, title, exclude_tokens=None):\n",
        "    all_tokens = [token for tokens in tokens_series for token in tokens]\n",
        "    if not all_tokens:\n",
        "        return\n",
        "\n",
        "    if exclude_tokens:\n",
        "        all_tokens = [token for token in all_tokens if token not in exclude_tokens]\n",
        "\n",
        "    if not all_tokens:\n",
        "        return\n",
        "\n",
        "    text = ' '.join(all_tokens)\n",
        "    wordcloud = WordCloud(\n",
        "        width=1200, height=600,\n",
        "        background_color='white',\n",
        "        max_words=100,\n",
        "        colormap='viridis'\n",
        "    ).generate(text)\n",
        "\n",
        "    plt.figure(figsize=(15, 7))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.title(title, fontsize=18, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "fresh_reviews = df[df['review_type'] == 'Fresh']\n",
        "rotten_reviews = df[df['review_type'] == 'Rotten']\n",
        "\n",
        "fresh_tokens = [token for tokens in fresh_reviews['tokens'] for token in tokens]\n",
        "rotten_tokens = [token for tokens in rotten_reviews['tokens'] for token in tokens]\n",
        "\n",
        "fresh_freq = pd.Series(fresh_tokens).value_counts()\n",
        "rotten_freq = pd.Series(rotten_tokens).value_counts()\n",
        "\n",
        "common_words = set(fresh_freq.index) & set(rotten_freq.index)\n",
        "\n",
        "generate_wordcloud(fresh_reviews['tokens'], 'Fresh Reviews - Distinctive Words', exclude_tokens=common_words)\n",
        "generate_wordcloud(rotten_reviews['tokens'], 'Rotten Reviews - Distinctive Words', exclude_tokens=common_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0sqFAg-jibV"
      },
      "outputs": [],
      "source": [
        "mismatched_df = df[~df['sentiment_matches']]\n",
        "\n",
        "print(f\"Liczba niezgodnych recenzji: {len(mismatched_df)} ({len(mismatched_df)/len(df)*100:.1f}%)\")\n",
        "\n",
        "mismatched_df[['review_type', 'predicted_sentiment', 'text_cleaned']].sample(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS7kgiz8kxRK"
      },
      "source": [
        "#//////LISTA ZMIAN PRZED NAUCZANIEM REGRESJI:\n",
        "\n",
        "- potencjalnie usunąć absurdalne przypadki pokroju \"recenzja napisana w roku 1800\", bo mogą psuć działanie modelu nr.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4vvVVva5bu6"
      },
      "source": [
        "#MODEL PREDYKCJI OCENY RECENZJI WSPOMAGANY SENTYMENTEM Z MODELU NR.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7o3IPIMSStFm"
      },
      "outputs": [],
      "source": [
        "# Parsowanie ocen do skali 0-100, a następnie na 1-10 (pierwsza skala służy do wizualizacji)\n",
        "print(\"\\nParsowanie ocen do skali 1-10\")\n",
        "\n",
        "GRADE_MAP = {\n",
        "    \"A+\": 100, \"A\": 95, \"A-\": 90,\n",
        "    \"B+\": 87,  \"B\": 83, \"B-\": 80,\n",
        "    \"C+\": 77,  \"C\": 73, \"C-\": 70,\n",
        "    \"D+\": 67,  \"D\": 63, \"D-\": 60,\n",
        "    \"F\": 50\n",
        "}\n",
        "\n",
        "def score_to_0_100(x):\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "\n",
        "    s = str(x).strip()\n",
        "\n",
        "    m = re.match(r\"^(\\d+(?:\\.\\d+)?)\\s*%$\", s)\n",
        "    if m:\n",
        "        return float(m.group(1))\n",
        "\n",
        "    m = re.match(r\"^(\\d+(?:\\.\\d+)?)\\s*/\\s*(\\d+(?:\\.\\d+)?)$\", s)\n",
        "    if m:\n",
        "        num, den = float(m.group(1)), float(m.group(2))\n",
        "        if den > 0:\n",
        "            return 100.0 * num / den\n",
        "\n",
        "    m = re.match(r\"^(\\d+(?:\\.\\d+)?)$\", s)\n",
        "    if m:\n",
        "        num = float(m.group(1))\n",
        "        if num <= 5:\n",
        "            return 100.0 * num / 5.0\n",
        "        elif num <= 10:\n",
        "            return num * 10.0\n",
        "        elif num <= 100:\n",
        "            return num\n",
        "\n",
        "    if s.upper().strip() in GRADE_MAP:\n",
        "        return float(GRADE_MAP[s.upper().strip()])\n",
        "\n",
        "    return np.nan\n",
        "\n",
        "df[\"score_100\"] = df[\"review_score\"].apply(score_to_0_100)\n",
        "df[\"score_10\"] = (df[\"score_100\"] / 10.0).round().clip(1, 10).astype('Int64')\n",
        "\n",
        "original_count = df[\"review_score\"].notna().sum()\n",
        "parsed_count = df[\"score_10\"].notna().sum()\n",
        "success_rate = (parsed_count / original_count * 100) if original_count > 0 else 0\n",
        "\n",
        "print(f\"   Oryginalne oceny: {original_count}\")\n",
        "print(f\"   Sparsowane: {parsed_count} ({success_rate:.1f}%)\")\n",
        "print(f\"\\n   Rozkład ocen (1-10):\")\n",
        "print(f\"      Średnia: {df['score_10'].mean():.1f}\")\n",
        "print(f\"      Mediana: {df['score_10'].median():.0f}\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "df[\"score_100\"].dropna().hist(bins=50, ax=axes[0], edgecolor='black', color='#4ECDC4')\n",
        "axes[0].set_xlabel(\"Score (0-100)\", fontsize=12)\n",
        "axes[0].set_ylabel(\"Count\", fontsize=12)\n",
        "axes[0].set_title(\"Original Scale (0-100)\", fontsize=13, fontweight='bold')\n",
        "axes[0].axvline(df[\"score_100\"].median(), color='red', linestyle='--',\n",
        "                label=f'Median: {df[\"score_100\"].median():.0f}')\n",
        "axes[0].legend()\n",
        "\n",
        "df[\"score_10\"].dropna().hist(bins=10, range=(0.5, 10.5), ax=axes[1],\n",
        "                              edgecolor='black', color='#45B7D1', align='mid')\n",
        "axes[1].set_xlabel(\"Score (1-10)\", fontsize=12)\n",
        "axes[1].set_ylabel(\"Count\", fontsize=12)\n",
        "axes[1].set_title(\"Transformed Scale (1-10, Integer)\", fontsize=13, fontweight='bold')\n",
        "axes[1].axvline(df[\"score_10\"].median(), color='red', linestyle='--',\n",
        "                label=f'Median: {df[\"score_10\"].median():.0f}')\n",
        "axes[1].legend()\n",
        "axes[1].set_xticks(range(1, 11))\n",
        "axes[1].set_xlim(0.5, 10.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziMv3lDGSduu"
      },
      "outputs": [],
      "source": [
        "# Analiza n-gramów i log-odds\n",
        "print(\"\\nAnaliza n-gramów i log-odds\")\n",
        "\n",
        "df_for_ngrams = df[\n",
        "    df[\"score_10\"].notna() &\n",
        "    (df[\"text_cleaned\"].str.strip() != \"\")\n",
        "].copy()\n",
        "\n",
        "print(f\"   Analizowanych recenzji: {len(df_for_ngrams)}\")\n",
        "print(f\"   Zakres ocen: {df_for_ngrams['score_10'].min():.0f} - {df_for_ngrams['score_10'].max():.0f}\")\n",
        "\n",
        "vectorizer_ngrams = TfidfVectorizer(\n",
        "    ngram_range=(1, 3), #Używane są uni-gramy, bi-gramy oraz tri-gramy\n",
        "    min_df=10,\n",
        "    max_features=20000,\n",
        "    sublinear_tf=True\n",
        ")\n",
        "\n",
        "X_ngrams = vectorizer_ngrams.fit_transform(df_for_ngrams[\"text_cleaned\"])\n",
        "y_ngrams = df_for_ngrams[\"score_10\"].astype(float)\n",
        "\n",
        "ridge_ngrams = Ridge(alpha=1.0)\n",
        "ridge_ngrams.fit(X_ngrams, y_ngrams)\n",
        "\n",
        "feature_names = vectorizer_ngrams.get_feature_names_out()\n",
        "coefficients = ridge_ngrams.coef_\n",
        "\n",
        "ngram_weights = pd.DataFrame({\n",
        "    'ngram': feature_names,\n",
        "    'log_odds': coefficients\n",
        "})\n",
        "\n",
        "ngram_weights = ngram_weights.sort_values('log_odds', ascending=False)\n",
        "\n",
        "print(\"\\n   TOP 30 n-gramów zwiększających ocenę:\")\n",
        "print(ngram_weights.head(30).to_string(index=False).replace('\\n', '\\n   '))\n",
        "\n",
        "print(\"\\n   TOP 30 n-gramów obniżających ocenę:\")\n",
        "print(ngram_weights.tail(30).to_string(index=False).replace('\\n', '\\n   '))\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "top_positive = ngram_weights.head(20)\n",
        "axes[0].barh(top_positive['ngram'], top_positive['log_odds'], color='#4ECDC4')\n",
        "axes[0].set_xlabel('Log-Odds (coefficient)', fontsize=12)\n",
        "axes[0].set_title('Top 20 N-grams Increasing Score', fontsize=14, fontweight='bold')\n",
        "axes[0].invert_yaxis()\n",
        "\n",
        "top_negative = ngram_weights.tail(20).sort_values('log_odds')\n",
        "axes[1].barh(top_negative['ngram'], top_negative['log_odds'], color='#FF6B6B')\n",
        "axes[1].set_xlabel('Log-Odds (coefficient)', fontsize=12)\n",
        "axes[1].set_title('Top 20 N-grams Decreasing Score', fontsize=14, fontweight='bold')\n",
        "axes[1].invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n   Łączna liczba cech: {len(feature_names)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McRiNY2_NPfv"
      },
      "outputs": [],
      "source": [
        "# Trening modelu regresji: tekst → ocena (1-10)\n",
        "print(\"\\nTrening modelu regresji: tekst → ocena (1-10)\")\n",
        "\n",
        "df_with_score = df[\n",
        "    df[\"score_10\"].notna() &\n",
        "    (df[\"text_cleaned\"].str.strip() != \"\")\n",
        "].copy()\n",
        "\n",
        "print(f\"   Dataset: {len(df_with_score)} recenzji\")\n",
        "print(f\"   Zakres ocen: {df_with_score['score_10'].min():.1f} - {df_with_score['score_10'].max():.1f}\")\n",
        "\n",
        "X = df_with_score[\"text_cleaned\"]\n",
        "y = df_with_score[\"score_10\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"   Train: {len(X_train)} | Test: {len(X_test)}\")\n",
        "\n",
        "regressor = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=2, max_features=30000)),\n",
        "    (\"ridge\", Ridge(alpha=1.0))\n",
        "])\n",
        "\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "pred_train = regressor.predict(X_train).clip(1, 10).round(1)\n",
        "pred_test = regressor.predict(X_test).clip(1, 10).round(1)\n",
        "\n",
        "mae_train = mean_absolute_error(y_train, pred_train)\n",
        "mae_test = mean_absolute_error(y_test, pred_test)\n",
        "rmse_test = mean_squared_error(y_test, pred_test) ** 0.5\n",
        "r2_test = r2_score(y_test, pred_test)\n",
        "\n",
        "print(f\"\\n   Train MAE: {mae_train:.3f}\")\n",
        "print(f\"   Test MAE:  {mae_test:.3f}\")\n",
        "print(f\"   Test RMSE: {rmse_test:.3f}\")\n",
        "print(f\"   Test R²:   {r2_test:.3f}\")\n",
        "\n",
        "# Tolerancja predykcji\n",
        "within_05 = (np.abs(y_test - pred_test) <= 0.5).mean()\n",
        "within_10 = (np.abs(y_test - pred_test) <= 1.0).mean()\n",
        "within_15 = (np.abs(y_test - pred_test) <= 1.5).mean()\n",
        "\n",
        "print(f\"\\n   Tolerancja predykcji:\")\n",
        "print(f\"      ±0.5 punktu: {within_05:.1%}\")\n",
        "print(f\"      ±1.0 punktu: {within_10:.1%}\")\n",
        "print(f\"      ±1.5 punktu: {within_15:.1%}\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "axes[0].scatter(y_test, pred_test, alpha=0.4, s=15, color='#4ECDC4')\n",
        "axes[0].plot([1, 10], [1, 10], 'r--', lw=2, label='Perfect prediction')\n",
        "axes[0].set_xlabel(\"Actual Score (1-10)\", fontsize=12)\n",
        "axes[0].set_ylabel(\"Predicted Score (1-10)\", fontsize=12)\n",
        "axes[0].set_title(\"Predicted vs Actual\", fontsize=13, fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "axes[0].set_xlim(0.5, 10.5)\n",
        "axes[0].set_ylim(0.5, 10.5)\n",
        "\n",
        "residuals = y_test - pred_test\n",
        "axes[1].hist(residuals, bins=40, edgecolor='black', color='#FF6B6B')\n",
        "axes[1].set_xlabel(\"Residual (Actual - Predicted)\", fontsize=12)\n",
        "axes[1].set_ylabel(\"Frequency\", fontsize=12)\n",
        "axes[1].set_title(\"Prediction Errors\", fontsize=13, fontweight='bold')\n",
        "axes[1].axvline(0, color='black', linestyle='--', linewidth=2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1pCCe4xNYte"
      },
      "outputs": [],
      "source": [
        "# Predykcja dla całego datasetu\n",
        "print(\"\\nPredykcja dla całego datasetu\")\n",
        "\n",
        "df[\"predicted_score_10\"] = np.nan\n",
        "mask = df[\"text_cleaned\"].notna() & (df[\"text_cleaned\"].str.strip() != \"\")\n",
        "\n",
        "df.loc[mask, \"predicted_score_10\"] = (\n",
        "    regressor.predict(df.loc[mask, \"text_cleaned\"])\n",
        "    .clip(1, 10)\n",
        "    .round(1)\n",
        ")\n",
        "\n",
        "print(f\"   Predykcje dla {mask.sum()} recenzji\")\n",
        "print(f\"\\n   Rozkład predykcji:\")\n",
        "print(f\"      Średnia: {df['predicted_score_10'].mean():.2f}\")\n",
        "print(f\"      Mediana: {df['predicted_score_10'].median():.1f}\")\n",
        "print(f\"      Min-Max: {df['predicted_score_10'].min():.1f} - {df['predicted_score_10'].max():.1f}\")\n",
        "\n",
        "df[\"score_residual\"] = df[\"score_10\"] - df[\"predicted_score_10\"]\n",
        "\n",
        "print(f\"\\n   Błąd predykcji (residuals):\")\n",
        "print(f\"      Średnia: {df['score_residual'].mean():.3f}\")\n",
        "print(f\"      Mediana: {df['score_residual'].median():.3f}\")\n",
        "print(f\"      Odch. std: {df['score_residual'].std():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFRaOUfyruVJ"
      },
      "source": [
        "#//////LISTA ZMIAN PO PREDYKCJI OCEN\n",
        "\n",
        "- zastanowić się nad określaniem czy znikoma różnica między ocenami recenzenta to dobra rzecz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8w5CtOdWCfL"
      },
      "source": [
        "#OCENA PODEJRZANEGO ZACHOWANIA RECENZENTA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WSx9DKvJ_V_"
      },
      "outputs": [],
      "source": [
        "# Detekcja burst activity recenzentów (7 dni)\n",
        "print(\"\\nDetekcja burst activity recenzentów\")\n",
        "\n",
        "def calculate_reviewer_burst(group):\n",
        "    group = group.sort_values('review_date').copy()\n",
        "    total_reviews = len(group)\n",
        "\n",
        "    counts_7d = []\n",
        "\n",
        "    for idx, row in group.iterrows():\n",
        "        current_time = row['review_date']\n",
        "        window_7d_start = current_time - timedelta(days=7)\n",
        "        count_7d = ((group['review_date'] >= window_7d_start) &\n",
        "                    (group['review_date'] <= current_time)).sum()\n",
        "        counts_7d.append(count_7d)\n",
        "\n",
        "    group['reviewer_reviews_last_7d'] = counts_7d\n",
        "    group['reviewer_burst_ratio_7d'] = group['reviewer_reviews_last_7d'] / total_reviews\n",
        "\n",
        "    return group\n",
        "\n",
        "df = df.groupby('critic_name', group_keys=False).apply(calculate_reviewer_burst)\n",
        "\n",
        "# Flagi burst (threshold: >10 recenzji w 7 dni)\n",
        "df['is_reviewer_burst_7d'] = df['reviewer_reviews_last_7d'] > 10\n",
        "df['is_reviewer_burst_normalized'] = df['reviewer_burst_ratio_7d'] > 0.3\n",
        "\n",
        "df['is_reviewer_burst_any'] = (\n",
        "    df['is_reviewer_burst_7d'] |\n",
        "    df['is_reviewer_burst_normalized']\n",
        ")\n",
        "\n",
        "print(f\"   Burst 7d (>10 recenzji): {df['is_reviewer_burst_7d'].sum()} ({df['is_reviewer_burst_7d'].mean()*100:.1f}%)\")\n",
        "print(f\"   Burst znormalizowany (>30% w 7d): {df['is_reviewer_burst_normalized'].sum()} ({df['is_reviewer_burst_normalized'].mean()*100:.1f}%)\")\n",
        "print(f\"   Łącznie burst: {df['is_reviewer_burst_any'].sum()} ({df['is_reviewer_burst_any'].mean()*100:.1f}%)\")\n",
        "\n",
        "# Analiza recenzentów z burst\n",
        "bursty_reviewers = df[df['is_reviewer_burst_any']].groupby('critic_name').agg({\n",
        "    'reviewer_reviews_last_7d': 'max',\n",
        "    'reviewer_burst_ratio_7d': 'max',\n",
        "    'review_date': ['min', 'max'],\n",
        "    'review_content': 'count'\n",
        "}).reset_index()\n",
        "\n",
        "bursty_reviewers.columns = ['critic_name', 'max_burst_7d', 'max_burst_ratio',\n",
        "                             'first_review', 'last_review', 'total_reviews']\n",
        "bursty_reviewers = bursty_reviewers.sort_values('max_burst_7d', ascending=False)\n",
        "\n",
        "print(f\"\\n   Recenzenci z burst: {len(bursty_reviewers)}\")\n",
        "print(f\"\\n   TOP 20 recenzentów z największym burst:\")\n",
        "print(bursty_reviewers.head(20).to_string(index=False))\n",
        "\n",
        "# Wizualizacja przykładowego recenzenta\n",
        "if len(bursty_reviewers) > 0:\n",
        "    example_reviewer = bursty_reviewers.iloc[0]['critic_name']\n",
        "    reviewer_data = df[df['critic_name'] == example_reviewer].sort_values('review_date')\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "    fig.suptitle(f'Burst Analysis: {example_reviewer}', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # Plot 1: Time series - reviews in last 7d\n",
        "    reviewer_data.set_index('review_date')['reviewer_reviews_last_7d'].plot(\n",
        "        ax=axes[0], color='orange', linewidth=2\n",
        "    )\n",
        "    axes[0].axhline(y=10, color='black', linestyle='--',\n",
        "                    linewidth=2, label='Burst threshold (10)')\n",
        "    axes[0].set_title('Reviews Published in Last 7 Days (Rolling)', fontweight='bold')\n",
        "    axes[0].set_ylabel('Reviews in last 7 days', fontsize=11)\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot 2: Daily distribution\n",
        "    daily_counts = reviewer_data['review_date'].dt.date.value_counts().sort_index()\n",
        "    daily_counts.plot(kind='bar', ax=axes[1], color='steelblue', width=0.8)\n",
        "    axes[1].set_title('Daily Review Count', fontweight='bold')\n",
        "    axes[1].set_ylabel('Number of Reviews', fontsize=11)\n",
        "    axes[1].set_xlabel('Date', fontsize=11)\n",
        "    axes[1].tick_params(axis='x', rotation=45)\n",
        "    axes[1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # Plot 3: Hourly distribution\n",
        "    if pd.api.types.is_datetime64_any_dtype(reviewer_data['review_date']):\n",
        "        hourly_counts = reviewer_data['review_date'].dt.hour.value_counts().sort_index()\n",
        "        hourly_counts.plot(kind='bar', ax=axes[2], color='#4ECDC4', width=0.8)\n",
        "        axes[2].set_title('Review Distribution by Hour of Day', fontweight='bold')\n",
        "        axes[2].set_ylabel('Number of Reviews', fontsize=11)\n",
        "        axes[2].set_xlabel('Hour (0-23)', fontsize=11)\n",
        "        axes[2].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n   Analiza dla '{example_reviewer}':\")\n",
        "    print(f\"      Łączne recenzje: {len(reviewer_data)}\")\n",
        "    print(f\"      Peak 7d burst: {reviewer_data['reviewer_reviews_last_7d'].max()}\")\n",
        "    print(f\"      Max burst ratio: {reviewer_data['reviewer_burst_ratio_7d'].max()*100:.1f}%\")\n",
        "    print(f\"      Recenzje w burst: {reviewer_data['is_reviewer_burst_any'].sum()}\")\n",
        "    print(f\"      Zakres aktywności: {(reviewer_data['review_date'].max() - reviewer_data['review_date'].min()).days} dni\")\n",
        "\n",
        "# Porównanie thresholds\n",
        "print(\"\\n   Porównanie thresholds (7 dni):\")\n",
        "print(f\"   {'Threshold':<12} {'Recenzje':<12} {'% Recenzji':<15} {'Recenzenci':<12}\")\n",
        "\n",
        "thresholds_7d = [5, 10, 15, 20, 30, 50]\n",
        "\n",
        "for thresh in thresholds_7d:\n",
        "    review_count = (df['reviewer_reviews_last_7d'] > thresh).sum()\n",
        "    review_pct = review_count / len(df) * 100\n",
        "    reviewer_count = df[df['reviewer_reviews_last_7d'] > thresh]['critic_name'].nunique()\n",
        "    print(f\"   >{thresh:<11} {review_count:<12} {review_pct:<15.2f}% {reviewer_count:<12}\")\n",
        "\n",
        "# Statystyki burst\n",
        "print(f\"\\n   Statystyki burst (7 dni):\")\n",
        "print(f\"      Średnia: {df['reviewer_reviews_last_7d'].mean():.2f}\")\n",
        "print(f\"      Mediana: {df['reviewer_reviews_last_7d'].median():.1f}\")\n",
        "print(f\"      95 percentyl: {df['reviewer_reviews_last_7d'].quantile(0.95):.1f}\")\n",
        "print(f\"      Max: {df['reviewer_reviews_last_7d'].max():.0f}\")\n",
        "\n",
        "# Histogram\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "df['reviewer_reviews_last_7d'].hist(bins=50, ax=ax, color='#FFA07A', edgecolor='black')\n",
        "ax.axvline(10, color='black', linestyle='--', linewidth=2, label='Threshold: 10')\n",
        "ax.set_xlabel('Reviews by Reviewer in 7 Days', fontsize=12)\n",
        "ax.set_ylabel('Frequency', fontsize=12)\n",
        "ax.set_title('Reviewer 7-Day Burst Distribution', fontsize=14, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.set_yscale('log')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zViZWxXzRgkQ"
      },
      "outputs": [],
      "source": [
        "#Statystyki recenzentów\n",
        "\n",
        "# 1. Podstawowe statystyki recenzenta\n",
        "reviewer_stats = df.groupby('critic_name').agg({\n",
        "    'review_date': ['count', 'min', 'max'],  # ile recenzji, zakres dat\n",
        "    'review_type': lambda x: (x == 'Fresh').mean(),  # % pozytywnych\n",
        "    'movie_title': 'nunique',  # ile różnych filmów\n",
        "    'score_10': ['mean', 'std'],  # średnia ocena, wariancja\n",
        "    'text_length_cleaned': 'mean'  # średnia długość tekstu\n",
        "}).reset_index()\n",
        "\n",
        "reviewer_stats.columns = ['critic_name', 'review_count', 'first_review',\n",
        "                          'last_review', 'positive_ratio', 'unique_movies',\n",
        "                          'avg_score', 'score_std', 'avg_text_length']\n",
        "\n",
        "# 2. Reviewer deviation (web:12) - jak różni się od średniej\n",
        "reviewer_stats['deviation_from_mean'] = np.abs(\n",
        "    reviewer_stats['avg_score'] - df['score_10'].mean()\n",
        ")\n",
        "\n",
        "# 3. Activity span\n",
        "reviewer_stats['days_active'] = (\n",
        "    reviewer_stats['last_review'] - reviewer_stats['first_review']\n",
        ").dt.days\n",
        "\n",
        "# 4. Suspicious patterns\n",
        "reviewer_stats['is_suspicious'] = (\n",
        "    (reviewer_stats['review_count'] < 5) |  # mało recenzji\n",
        "    (reviewer_stats['positive_ratio'] > 0.95) |  # tylko pozytywne\n",
        "    (reviewer_stats['positive_ratio'] < 0.05) |  # tylko negatywne\n",
        "    (reviewer_stats['days_active'] < 30)  # krótki okres aktywności\n",
        ")\n",
        "\n",
        "# 5. Merge z głównym df\n",
        "df = df.merge(reviewer_stats, on='critic_name', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIPImIJEZHFs"
      },
      "outputs": [],
      "source": [
        "# Wizualizacja statystyk recenzentów\n",
        "print(\"\\nWizualizacja statystyk recenzentów\")\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# VIZ 1: Podstawowe metryki\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('Reviewer Statistics Overview', fontsize=16, fontweight='bold', y=0.995)\n",
        "\n",
        "axes[0, 0].hist(reviewer_stats['review_count'], bins=50, color='#4ECDC4', edgecolor='black')\n",
        "axes[0, 0].axvline(reviewer_stats['review_count'].median(), color='red',\n",
        "                   linestyle='--', label=f\"Median: {reviewer_stats['review_count'].median():.0f}\")\n",
        "axes[0, 0].set_xlabel('Number of Reviews', fontsize=11)\n",
        "axes[0, 0].set_ylabel('Number of Reviewers', fontsize=11)\n",
        "axes[0, 0].set_title('Distribution of Review Count per Reviewer', fontweight='bold')\n",
        "axes[0, 0].set_yscale('log')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "axes[0, 1].hist(reviewer_stats['positive_ratio'], bins=30, color='#45B7D1', edgecolor='black')\n",
        "axes[0, 1].axvline(0.5, color='green', linestyle='--', label='Balanced (50%)')\n",
        "axes[0, 1].axvline(0.95, color='red', linestyle='--', label='Suspicious (>95%)')\n",
        "axes[0, 1].axvline(0.05, color='red', linestyle='--', label='Suspicious (<5%)')\n",
        "axes[0, 1].set_xlabel('Positive Review Ratio', fontsize=11)\n",
        "axes[0, 1].set_ylabel('Number of Reviewers', fontsize=11)\n",
        "axes[0, 1].set_title('Fresh/Rotten Ratio Distribution', fontweight='bold')\n",
        "axes[0, 1].legend(fontsize=9)\n",
        "\n",
        "axes[0, 2].hist(reviewer_stats['days_active'], bins=50, color='#FF6B6B', edgecolor='black')\n",
        "axes[0, 2].axvline(30, color='red', linestyle='--', label='Suspicious (<30 days)')\n",
        "axes[0, 2].set_xlabel('Days Active', fontsize=11)\n",
        "axes[0, 2].set_ylabel('Number of Reviewers', fontsize=11)\n",
        "axes[0, 2].set_title('Reviewer Activity Span', fontweight='bold')\n",
        "axes[0, 2].legend()\n",
        "\n",
        "axes[1, 0].hist(reviewer_stats['avg_score'].dropna(), bins=30, color='#95E1D3', edgecolor='black')\n",
        "axes[1, 0].axvline(reviewer_stats['avg_score'].mean(), color='red',\n",
        "                   linestyle='--', label=f\"Mean: {reviewer_stats['avg_score'].mean():.2f}\")\n",
        "axes[1, 0].set_xlabel('Average Score (1-10)', fontsize=11)\n",
        "axes[1, 0].set_ylabel('Number of Reviewers', fontsize=11)\n",
        "axes[1, 0].set_title('Average Reviewer Score Distribution', fontweight='bold')\n",
        "axes[1, 0].legend()\n",
        "\n",
        "axes[1, 1].hist(reviewer_stats['score_std'].dropna(), bins=30, color='#F38181', edgecolor='black')\n",
        "axes[1, 1].set_xlabel('Score Standard Deviation', fontsize=11)\n",
        "axes[1, 1].set_ylabel('Number of Reviewers', fontsize=11)\n",
        "axes[1, 1].set_title('Score Variability per Reviewer', fontweight='bold')\n",
        "\n",
        "axes[1, 2].hist(reviewer_stats['unique_movies'], bins=50, color='#AA96DA', edgecolor='black')\n",
        "axes[1, 2].set_xlabel('Number of Unique Movies', fontsize=11)\n",
        "axes[1, 2].set_ylabel('Number of Reviewers', fontsize=11)\n",
        "axes[1, 2].set_title('Movies Reviewed per Critic', fontweight='bold')\n",
        "axes[1, 2].set_yscale('log')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# VIZ 2: Suspicious vs Normal\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Suspicious vs Normal Reviewers Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "suspicious = reviewer_stats[reviewer_stats['is_suspicious']]\n",
        "normal = reviewer_stats[~reviewer_stats['is_suspicious']]\n",
        "\n",
        "print(f\"   Podejrzani: {len(suspicious)} ({len(suspicious)/len(reviewer_stats)*100:.1f}%)\")\n",
        "print(f\"   Normalni: {len(normal)} ({len(normal)/len(reviewer_stats)*100:.1f}%)\")\n",
        "\n",
        "data_to_plot = [normal['review_count'], suspicious['review_count']]\n",
        "bp1 = axes[0, 0].boxplot(data_to_plot, labels=['Normal', 'Suspicious'],\n",
        "                          patch_artist=True, widths=0.6)\n",
        "bp1['boxes'][0].set_facecolor('#4ECDC4')\n",
        "bp1['boxes'][1].set_facecolor('#FF6B6B')\n",
        "axes[0, 0].set_ylabel('Review Count', fontsize=11)\n",
        "axes[0, 0].set_title('Review Count: Normal vs Suspicious', fontweight='bold')\n",
        "axes[0, 0].set_yscale('log')\n",
        "\n",
        "data_to_plot = [normal['positive_ratio'], suspicious['positive_ratio']]\n",
        "bp2 = axes[0, 1].boxplot(data_to_plot, labels=['Normal', 'Suspicious'],\n",
        "                          patch_artist=True, widths=0.6)\n",
        "bp2['boxes'][0].set_facecolor('#4ECDC4')\n",
        "bp2['boxes'][1].set_facecolor('#FF6B6B')\n",
        "axes[0, 1].set_ylabel('Positive Ratio', fontsize=11)\n",
        "axes[0, 1].set_title('Fresh Ratio: Normal vs Suspicious', fontweight='bold')\n",
        "axes[0, 1].axhline(0.5, color='green', linestyle='--', alpha=0.5)\n",
        "\n",
        "data_to_plot = [normal['days_active'], suspicious['days_active']]\n",
        "bp3 = axes[1, 0].boxplot(data_to_plot, labels=['Normal', 'Suspicious'],\n",
        "                          patch_artist=True, widths=0.6)\n",
        "bp3['boxes'][0].set_facecolor('#4ECDC4')\n",
        "bp3['boxes'][1].set_facecolor('#FF6B6B')\n",
        "axes[1, 0].set_ylabel('Days Active', fontsize=11)\n",
        "axes[1, 0].set_title('Activity Span: Normal vs Suspicious', fontweight='bold')\n",
        "\n",
        "data_to_plot = [normal['deviation_from_mean'].dropna(), suspicious['deviation_from_mean'].dropna()]\n",
        "bp4 = axes[1, 1].boxplot(data_to_plot, labels=['Normal', 'Suspicious'],\n",
        "                          patch_artist=True, widths=0.6)\n",
        "bp4['boxes'][0].set_facecolor('#4ECDC4')\n",
        "bp4['boxes'][1].set_facecolor('#FF6B6B')\n",
        "axes[1, 1].set_ylabel('Score Deviation from Mean', fontsize=11)\n",
        "axes[1, 1].set_title('Score Deviation: Normal vs Suspicious', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# VIZ 3: Scatter plots - zależności\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Reviewer Behavior Patterns', fontsize=16, fontweight='bold')\n",
        "\n",
        "axes[0, 0].scatter(normal['review_count'], normal['positive_ratio'],\n",
        "                   alpha=0.5, s=30, color='#4ECDC4', label='Normal')\n",
        "axes[0, 0].scatter(suspicious['review_count'], suspicious['positive_ratio'],\n",
        "                   alpha=0.7, s=50, color='#FF6B6B', marker='x', label='Suspicious')\n",
        "axes[0, 0].axhline(0.95, color='red', linestyle='--', alpha=0.3)\n",
        "axes[0, 0].axhline(0.05, color='red', linestyle='--', alpha=0.3)\n",
        "axes[0, 0].axvline(5, color='red', linestyle='--', alpha=0.3)\n",
        "axes[0, 0].set_xlabel('Review Count', fontsize=11)\n",
        "axes[0, 0].set_ylabel('Positive Ratio', fontsize=11)\n",
        "axes[0, 0].set_title('Review Count vs Sentiment Bias', fontweight='bold')\n",
        "axes[0, 0].set_xscale('log')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[0, 1].scatter(normal['days_active'], normal['review_count'],\n",
        "                   alpha=0.5, s=30, color='#4ECDC4', label='Normal')\n",
        "axes[0, 1].scatter(suspicious['days_active'], suspicious['review_count'],\n",
        "                   alpha=0.7, s=50, color='#FF6B6B', marker='x', label='Suspicious')\n",
        "axes[0, 1].axvline(30, color='red', linestyle='--', alpha=0.3, label='30-day threshold')\n",
        "axes[0, 1].set_xlabel('Days Active', fontsize=11)\n",
        "axes[0, 1].set_ylabel('Review Count', fontsize=11)\n",
        "axes[0, 1].set_title('Activity Duration vs Volume', fontweight='bold')\n",
        "axes[0, 1].set_yscale('log')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1, 0].scatter(normal['avg_score'], normal['score_std'],\n",
        "                   alpha=0.5, s=30, color='#4ECDC4', label='Normal')\n",
        "axes[1, 0].scatter(suspicious['avg_score'], suspicious['score_std'],\n",
        "                   alpha=0.7, s=50, color='#FF6B6B', marker='x', label='Suspicious')\n",
        "axes[1, 0].set_xlabel('Average Score', fontsize=11)\n",
        "axes[1, 0].set_ylabel('Score Standard Deviation', fontsize=11)\n",
        "axes[1, 0].set_title('Score Consistency Pattern', fontweight='bold')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1, 1].scatter(normal['unique_movies'], normal['review_count'],\n",
        "                   alpha=0.5, s=30, color='#4ECDC4', label='Normal')\n",
        "axes[1, 1].scatter(suspicious['unique_movies'], suspicious['review_count'],\n",
        "                   alpha=0.7, s=50, color='#FF6B6B', marker='x', label='Suspicious')\n",
        "max_val = max(reviewer_stats['unique_movies'].max(), reviewer_stats['review_count'].max())\n",
        "axes[1, 1].plot([0, max_val], [0, max_val], 'g--', alpha=0.3, label='1:1 ratio')\n",
        "axes[1, 1].set_xlabel('Unique Movies Reviewed', fontsize=11)\n",
        "axes[1, 1].set_ylabel('Total Review Count', fontsize=11)\n",
        "axes[1, 1].set_title('Review Diversity Pattern', fontweight='bold')\n",
        "axes[1, 1].set_xscale('log')\n",
        "axes[1, 1].set_yscale('log')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# VIZ 4: TOP/BOTTOM recenzenci\n",
        "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
        "fig.suptitle('Extreme Reviewers Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "top_active = reviewer_stats.nlargest(20, 'review_count')\n",
        "axes[0, 0].barh(range(len(top_active)), top_active['review_count'], color='#4ECDC4')\n",
        "axes[0, 0].set_yticks(range(len(top_active)))\n",
        "axes[0, 0].set_yticklabels(top_active['critic_name'], fontsize=8)\n",
        "axes[0, 0].set_xlabel('Review Count', fontsize=11)\n",
        "axes[0, 0].set_title('Top 20 Most Active Reviewers', fontweight='bold')\n",
        "axes[0, 0].invert_yaxis()\n",
        "\n",
        "most_positive = reviewer_stats[reviewer_stats['review_count'] >= 10].nlargest(20, 'positive_ratio')\n",
        "axes[0, 1].barh(range(len(most_positive)), most_positive['positive_ratio']*100, color='#00EA6E')\n",
        "axes[0, 1].set_yticks(range(len(most_positive)))\n",
        "axes[0, 1].set_yticklabels(most_positive['critic_name'], fontsize=8)\n",
        "axes[0, 1].set_xlabel('Fresh Review % (min 10 reviews)', fontsize=11)\n",
        "axes[0, 1].set_title('Top 20 Most Positive Reviewers', fontweight='bold')\n",
        "axes[0, 1].invert_yaxis()\n",
        "\n",
        "most_negative = reviewer_stats[reviewer_stats['review_count'] >= 10].nsmallest(20, 'positive_ratio')\n",
        "axes[1, 0].barh(range(len(most_negative)), most_negative['positive_ratio']*100, color='#FF3B3F')\n",
        "axes[1, 0].set_yticks(range(len(most_negative)))\n",
        "axes[1, 0].set_yticklabels(most_negative['critic_name'], fontsize=8)\n",
        "axes[1, 0].set_xlabel('Fresh Review % (min 10 reviews)', fontsize=11)\n",
        "axes[1, 0].set_title('Top 20 Most Negative Reviewers', fontweight='bold')\n",
        "axes[1, 0].invert_yaxis()\n",
        "\n",
        "top_deviation = reviewer_stats[reviewer_stats['review_count'] >= 10].nlargest(20, 'deviation_from_mean')\n",
        "axes[1, 1].barh(range(len(top_deviation)), top_deviation['deviation_from_mean'], color='#F38181')\n",
        "axes[1, 1].set_yticks(range(len(top_deviation)))\n",
        "axes[1, 1].set_yticklabels(top_deviation['critic_name'], fontsize=8)\n",
        "axes[1, 1].set_xlabel('Score Deviation from Mean (min 10 reviews)', fontsize=11)\n",
        "axes[1, 1].set_title('Top 20 Most Extreme Scorers', fontweight='bold')\n",
        "axes[1, 1].invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Podsumowanie statystyk\n",
        "print(\"\\nPodsumowanie statystyk recenzentów:\")\n",
        "\n",
        "summary_data = {\n",
        "    'Metric': ['Total Reviewers', 'Suspicious Reviewers', 'Avg Reviews per Critic',\n",
        "               'Median Reviews', 'Avg Positive Ratio', 'Avg Days Active',\n",
        "               'Avg Unique Movies', 'Avg Score Deviation'],\n",
        "    'All Reviewers': [\n",
        "        len(reviewer_stats),\n",
        "        f\"{len(suspicious)} ({len(suspicious)/len(reviewer_stats)*100:.1f}%)\",\n",
        "        f\"{reviewer_stats['review_count'].mean():.1f}\",\n",
        "        f\"{reviewer_stats['review_count'].median():.0f}\",\n",
        "        f\"{reviewer_stats['positive_ratio'].mean()*100:.1f}%\",\n",
        "        f\"{reviewer_stats['days_active'].mean():.0f}\",\n",
        "        f\"{reviewer_stats['unique_movies'].mean():.1f}\",\n",
        "        f\"{reviewer_stats['deviation_from_mean'].mean():.2f}\"\n",
        "    ],\n",
        "    'Normal': [\n",
        "        len(normal),\n",
        "        \"-\",\n",
        "        f\"{normal['review_count'].mean():.1f}\",\n",
        "        f\"{normal['review_count'].median():.0f}\",\n",
        "        f\"{normal['positive_ratio'].mean()*100:.1f}%\",\n",
        "        f\"{normal['days_active'].mean():.0f}\",\n",
        "        f\"{normal['unique_movies'].mean():.1f}\",\n",
        "        f\"{normal['deviation_from_mean'].mean():.2f}\"\n",
        "    ],\n",
        "    'Suspicious': [\n",
        "        len(suspicious),\n",
        "        f\"{len(suspicious)} (100%)\",\n",
        "        f\"{suspicious['review_count'].mean():.1f}\",\n",
        "        f\"{suspicious['review_count'].median():.0f}\",\n",
        "        f\"{suspicious['positive_ratio'].mean()*100:.1f}%\",\n",
        "        f\"{suspicious['days_active'].mean():.0f}\",\n",
        "        f\"{suspicious['unique_movies'].mean():.1f}\",\n",
        "        f\"{suspicious['deviation_from_mean'].mean():.2f}\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(summary_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hA2svjgAkp4H"
      },
      "outputs": [],
      "source": [
        "# Obliczanie wskaźnika podejrzliwości recenzenta (1-10)\n",
        "print(\"\\nObliczanie wskaźnika podejrzliwości recenzenta\")\n",
        "\n",
        "def calculate_reviewer_suspicious_score(df):\n",
        "    reviewer_stats = df.groupby('critic_name').agg({\n",
        "        'critic_name': 'count',\n",
        "        'review_type_encoded': 'mean',\n",
        "        'score_10': ['mean', 'std'],\n",
        "        'is_reviewer_burst_7d': 'sum',\n",
        "        'days_since_release': 'mean',\n",
        "    }).reset_index()\n",
        "\n",
        "    reviewer_stats.columns = ['critic_name', 'review_count', 'positive_ratio',\n",
        "                               'score_mean', 'score_std', 'burst_count', 'avg_days_since_release']\n",
        "\n",
        "    # Wysoki burst = podejrzane\n",
        "    burst_score = np.clip(reviewer_stats['burst_count'] / 5, 0, 1)\n",
        "\n",
        "    # Bardzo dużo recenzji = podejrzane\n",
        "    velocity_score = np.clip((reviewer_stats['review_count'] - 10) / 100, 0, 1)\n",
        "\n",
        "    # Skrajne positive_ratio (blisko 0 lub 1) = podejrzane\n",
        "    bias_score = np.abs(reviewer_stats['positive_ratio'] - 0.5) * 2\n",
        "\n",
        "    # Bardzo niskie std = podejrzane (bot-like behavior)\n",
        "    consistency_score = 1 - np.clip(reviewer_stats['score_std'] / 2.5, 0, 1)\n",
        "\n",
        "    # Częste bardzo wczesne recenzje = podejrzane\n",
        "    early_score = np.clip((7 - reviewer_stats['avg_days_since_release']) / 7, 0, 1)\n",
        "    early_score = np.maximum(early_score, 0)\n",
        "\n",
        "    weights = {\n",
        "        'burst': 0.30,       # Najważniejszy sygnał\n",
        "        'velocity': 0.15,\n",
        "        'bias': 0.25,        # Drugi najważniejszy\n",
        "        'consistency': 0.20,\n",
        "        'early': 0.10\n",
        "    }\n",
        "\n",
        "    suspicious_raw = (\n",
        "        weights['burst'] * burst_score +\n",
        "        weights['velocity'] * velocity_score +\n",
        "        weights['bias'] * bias_score +\n",
        "        weights['consistency'] * consistency_score +\n",
        "        weights['early'] * early_score\n",
        "    )\n",
        "\n",
        "    # Skalowanie 1-10\n",
        "    reviewer_stats['suspicious_score'] = 1 + (suspicious_raw * 9)\n",
        "\n",
        "    df = df.merge(\n",
        "        reviewer_stats[['critic_name', 'suspicious_score']],\n",
        "        on='critic_name',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    return df, reviewer_stats\n",
        "\n",
        "df, reviewer_stats = calculate_reviewer_suspicious_score(df)\n",
        "\n",
        "print(f\"   Średni wskaźnik: {df['suspicious_score'].mean():.2f}\")\n",
        "print(f\"   Zakres: {df['suspicious_score'].min():.2f} - {df['suspicious_score'].max():.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNRIqk49yzrJ"
      },
      "outputs": [],
      "source": [
        "# Histogram + Top 20\n",
        "print(\"\\nAnaliza wskaźnika podejrzliwości\")\n",
        "\n",
        "print(f\"   Łącznie recenzentów: {len(reviewer_stats)}\")\n",
        "print(f\"   Wysoko podejrzani (>7): {(reviewer_stats['suspicious_score'] > 7).sum()} ({(reviewer_stats['suspicious_score'] > 7).sum()/len(reviewer_stats)*100:.1f}%)\")\n",
        "print(f\"   Średnia: {reviewer_stats['suspicious_score'].mean():.2f}\")\n",
        "print(f\"   Mediana: {reviewer_stats['suspicious_score'].median():.2f}\")\n",
        "\n",
        "# Wizualizacja\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# 1. Histogram\n",
        "axes[0].hist(reviewer_stats['suspicious_score'], bins=30, edgecolor='black',\n",
        "            color='#FF6B6B', alpha=0.7)\n",
        "axes[0].axvline(reviewer_stats['suspicious_score'].median(),\n",
        "               color='blue', linestyle='--', linewidth=2,\n",
        "               label=f\"Median: {reviewer_stats['suspicious_score'].median():.2f}\")\n",
        "axes[0].axvline(reviewer_stats['suspicious_score'].mean(),\n",
        "               color='green', linestyle='--', linewidth=2,\n",
        "               label=f\"Mean: {reviewer_stats['suspicious_score'].mean():.2f}\")\n",
        "axes[0].set_xlabel('Suspicious Score (1-10)', fontsize=12)\n",
        "axes[0].set_ylabel('Number of Reviewers', fontsize=12)\n",
        "axes[0].set_title('Distribution of Reviewer Suspicious Scores',\n",
        "                 fontsize=14, fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "axes[0].set_xlim(0, 11)\n",
        "\n",
        "# 2. Top 20 bar chart\n",
        "top_20_suspicious = reviewer_stats.nlargest(20, 'suspicious_score')\n",
        "axes[1].barh(range(20), top_20_suspicious['suspicious_score'].values,\n",
        "            color='#FF3B3F', edgecolor='black')\n",
        "axes[1].set_yticks(range(20))\n",
        "axes[1].set_yticklabels(top_20_suspicious['critic_name'].values, fontsize=9)\n",
        "axes[1].set_xlabel('Suspicious Score', fontsize=12)\n",
        "axes[1].set_title('Top 20 Most Suspicious Critics',\n",
        "                 fontsize=14, fontweight='bold')\n",
        "axes[1].invert_yaxis()\n",
        "axes[1].grid(axis='x', alpha=0.3)\n",
        "axes[1].axvline(7, color='orange', linestyle='--', linewidth=1.5,\n",
        "               alpha=0.7, label='High suspicion threshold')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJYo-ESuLSl7"
      },
      "source": [
        "#STATYSTYKI PODEJRZANOŚCI FILMÓW I PRODUCENTÓW FILMOWYCH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDZrjb-1L-yF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "SUS_TH = 7.0\n",
        "# alternatywnie: SUS_TH = df['suspicious_score'].quantile(0.995)\n",
        "\n",
        "df['is_suspicious_reviewer'] = (\n",
        "    (df['suspicious_score'] >= SUS_TH)\n",
        "    .fillna(False)\n",
        "    .astype(int)\n",
        ")\n",
        "\n",
        "movie_susp = (\n",
        "    df.groupby('movie_title')\n",
        "      .agg(\n",
        "          suspicious_reviews=('is_suspicious_reviewer', 'sum'),\n",
        "          total_reviews=('is_suspicious_reviewer', 'size'),\n",
        "          suspicious_ratio=('is_suspicious_reviewer', 'mean'),\n",
        "          suspicious_reviewers=('critic_name', lambda s: s[df.loc[s.index, 'is_suspicious_reviewer'].eq(1)].nunique())\n",
        "      )\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "MIN_TOTAL = 10\n",
        "movie_susp = movie_susp[movie_susp['total_reviews'] >= MIN_TOTAL].copy()\n",
        "\n",
        "movie_susp = movie_susp.sort_values(\n",
        "    ['suspicious_reviews', 'suspicious_ratio', 'total_reviews'],\n",
        "    ascending=[False, False, False]\n",
        ")\n",
        "\n",
        "movie_susp.head(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOWg9xu9bAHy"
      },
      "outputs": [],
      "source": [
        "movie_susp_studio = movie_susp.merge(\n",
        "    movies_df[['movie_title', 'production_company']].drop_duplicates(),\n",
        "    on='movie_title',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "movie_susp_studio.head(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zbOluzebDJr"
      },
      "outputs": [],
      "source": [
        "# suma podejrzanych recenzji per studio\n",
        "studio_rank = (\n",
        "    movie_susp_studio\n",
        "      .groupby('production_company', dropna=False)\n",
        "      .agg(\n",
        "          suspicious_reviews=('suspicious_reviews', 'sum'),\n",
        "          total_reviews=('total_reviews', 'sum'),\n",
        "          suspicious_ratio=('suspicious_ratio', 'mean'),   # średnia z filmów\n",
        "          movies=('movie_title', 'nunique')\n",
        "      )\n",
        "      .reset_index()\n",
        "      .sort_values(['suspicious_reviews', 'movies'], ascending=[False, False])\n",
        ")\n",
        "\n",
        "studio_rank.head(20)\n",
        "\n",
        "# Studia najczęściej występujące w TOP-N filmów\n",
        "TOP_N = 200\n",
        "topN = movie_susp_studio.head(TOP_N)\n",
        "\n",
        "studio_topN = (\n",
        "    topN.groupby('production_company', dropna=False)\n",
        "        .agg(\n",
        "            movies_in_topN=('movie_title', 'nunique'),\n",
        "            suspicious_reviews_in_topN=('suspicious_reviews', 'sum')\n",
        "        )\n",
        "        .reset_index()\n",
        "        .sort_values(['movies_in_topN', 'suspicious_reviews_in_topN'], ascending=[False, False])\n",
        ")\n",
        "\n",
        "studio_topN.head(20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpwEQf-Qk_mo"
      },
      "source": [
        "# MODEL 3 //////////\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WbFCeP4k_wP"
      },
      "outputs": [],
      "source": [
        "# Hybrid Isolation Forest - detekcja fałszywych recenzji\n",
        "print(\"\\nHybrid Isolation Forest - detekcja fałszywych recenzji\")\n",
        "\n",
        "numerical_features = [\n",
        "    'reviewer_reviews_last_7d',\n",
        "    'reviewer_burst_ratio_7d',\n",
        "    'positive_ratio',\n",
        "    'score_std',\n",
        "    'days_since_release',\n",
        "    'lexical_diversity',\n",
        "    'avg_word_length',\n",
        "    'word_count',\n",
        "    'score_residual',\n",
        "    'suspicious_score'\n",
        "]\n",
        "\n",
        "optional_features = [\n",
        "    'is_reviewer_burst_any',\n",
        "    'days_active',\n",
        "    'unique_movies',\n",
        "    'review_count',\n",
        "    'sentence_count'\n",
        "]\n",
        "\n",
        "use_optional = True\n",
        "\n",
        "if use_optional:\n",
        "    available_optional = [f for f in optional_features if f in df.columns]\n",
        "    all_features = numerical_features + available_optional\n",
        "    print(f\"   Cechy: {len(numerical_features)} podstawowe + {len(available_optional)} opcjonalne = {len(all_features)}\")\n",
        "else:\n",
        "    all_features = numerical_features\n",
        "    print(f\"   Cechy: {len(all_features)} podstawowe\")\n",
        "\n",
        "# Filtracja danych\n",
        "required_cols = ['text_cleaned'] + numerical_features\n",
        "df_model3 = df[df[required_cols].notna().all(axis=1)].copy()\n",
        "\n",
        "print(f\"   Dataset: {len(df_model3):,} recenzji ({len(df_model3)/len(df)*100:.1f}%)\")\n",
        "\n",
        "# Uzupełnienie braków w optional features\n",
        "if use_optional:\n",
        "    for col in available_optional:\n",
        "        if df_model3[col].isna().sum() > 0:\n",
        "            if df_model3[col].dtype == bool or df_model3[col].nunique() == 2:\n",
        "                df_model3[col] = df_model3[col].fillna(0).astype(int)\n",
        "            else:\n",
        "                df_model3[col] = df_model3[col].fillna(df_model3[col].median())\n",
        "\n",
        "X_numerical = df_model3[all_features].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
        "\n",
        "print(f\"   Przygotowano cechy numeryczne: {X_numerical_scaled.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyGTe4qVz7Yf"
      },
      "outputs": [],
      "source": [
        "# Generowanie embeddingów tekstowych (BERT)\n",
        "print(\"\\n   Generowanie embeddingów BERT (all-MiniLM-L6-v2, 384 dims)...\")\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "text_list = df_model3['text_cleaned'].tolist()\n",
        "\n",
        "text_embeddings = model.encode(\n",
        "    text_list,\n",
        "    batch_size=64,\n",
        "    show_progress_bar=True,\n",
        "    convert_to_numpy=True,\n",
        "    normalize_embeddings=True\n",
        ")\n",
        "\n",
        "print(f\"   Embeddingi: {text_embeddings.shape}\")\n",
        "\n",
        "# Redukcja wymiarowości (UMAP)\n",
        "print(\"\\n   Redukcja UMAP (384 → 10 dims)...\")\n",
        "\n",
        "reducer = umap.UMAP(\n",
        "    n_components=10,\n",
        "    n_neighbors=15,\n",
        "    min_dist=0.1,\n",
        "    metric='cosine',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "text_embeddings_reduced = reducer.fit_transform(text_embeddings)\n",
        "\n",
        "print(f\"   Po redukcji: {text_embeddings_reduced.shape}\")\n",
        "\n",
        "# Łączenie cech\n",
        "print(\"\\n   Łączenie cech numerycznych + tekstowych...\")\n",
        "\n",
        "combined_features = np.hstack([\n",
        "    X_numerical_scaled,\n",
        "    text_embeddings_reduced\n",
        "])\n",
        "\n",
        "print(f\"   Finalna macierz: {combined_features.shape}\")\n",
        "print(f\"   Skład: {X_numerical_scaled.shape[1]} numeryczne + {text_embeddings_reduced.shape[1]} tekstowe\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk8ons100AqQ"
      },
      "outputs": [],
      "source": [
        "# Trening Isolation Forest\n",
        "print(\"\\n   Trening Isolation Forest...\")\n",
        "\n",
        "contamination = 0.05\n",
        "n_estimators = 200\n",
        "max_samples = 256\n",
        "\n",
        "print(f\"      Contamination: {contamination*100:.1f}%\")\n",
        "print(f\"      Estimators: {n_estimators}\")\n",
        "print(f\"      Max samples: {max_samples}\")\n",
        "\n",
        "iso_forest = IsolationForest(\n",
        "    contamination=contamination,\n",
        "    n_estimators=n_estimators,\n",
        "    max_samples=max_samples,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "iso_forest.fit(combined_features)\n",
        "\n",
        "anomaly_scores = iso_forest.decision_function(combined_features)\n",
        "predictions = iso_forest.predict(combined_features)\n",
        "\n",
        "# Przetwarzanie wyników\n",
        "df_model3['anomaly_score'] = anomaly_scores\n",
        "df_model3['is_fake_review'] = (predictions == -1).astype(int)\n",
        "\n",
        "min_score = anomaly_scores.min()\n",
        "max_score = anomaly_scores.max()\n",
        "df_model3['fraud_probability'] = 100 * (1 - (anomaly_scores - min_score) / (max_score - min_score))\n",
        "\n",
        "fake_count = df_model3['is_fake_review'].sum()\n",
        "fake_pct = fake_count / len(df_model3) * 100\n",
        "\n",
        "print(f\"\\n   Wykryto:\")\n",
        "print(f\"      Łącznie recenzji: {len(df_model3):,}\")\n",
        "print(f\"      Fałszywe: {fake_count:,} ({fake_pct:.2f}%)\")\n",
        "print(f\"      Prawdziwe: {len(df_model3) - fake_count:,} ({100-fake_pct:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXDuXNH30FUY"
      },
      "outputs": [],
      "source": [
        "# Analiza wyników\n",
        "print(\"\\n   Analiza wyników...\")\n",
        "\n",
        "top_n = 100\n",
        "top_suspicious = df_model3.nlargest(top_n, 'fraud_probability')\n",
        "\n",
        "print(f\"\\n   Top {top_n} najbardziej podejrzanych recenzji:\")\n",
        "\n",
        "display_cols = ['fraud_probability', 'reviewer_reviews_last_7d', 'positive_ratio',\n",
        "                'days_since_release', 'lexical_diversity', 'text_cleaned']\n",
        "available_display = [col for col in display_cols if col in top_suspicious.columns]\n",
        "\n",
        "for i, (idx, row) in enumerate(top_suspicious.head(10).iterrows(), 1):\n",
        "    print(f\"\\n   {i}. Prawdopodobieństwo: {row['fraud_probability']:.1f}%\")\n",
        "    print(f\"      Tekst: {row['text_cleaned'][:100]}...\")\n",
        "    print(f\"      Burst 7d: {row.get('reviewer_reviews_last_7d', 'N/A')}, \"\n",
        "          f\"Positive ratio: {row.get('positive_ratio', 'N/A'):.2f}, \"\n",
        "          f\"Dni od premiery: {row.get('days_since_release', 'N/A')}\")\n",
        "\n",
        "# Porównanie fake vs legit\n",
        "print(\"\\n   Porównanie cech: Fake vs Legit\")\n",
        "\n",
        "fake_df = df_model3[df_model3['is_fake_review'] == 1]\n",
        "legit_df = df_model3[df_model3['is_fake_review'] == 0]\n",
        "\n",
        "comparison_features = ['reviewer_reviews_last_7d', 'positive_ratio', 'lexical_diversity',\n",
        "                       'days_since_release', 'score_std']\n",
        "available_comparison = [f for f in comparison_features if f in df_model3.columns]\n",
        "\n",
        "print(f\"\\n   {'Cecha':<30} {'Fake (śr.)':<15} {'Legit (śr.)':<15} {'Różnica':<15}\")\n",
        "\n",
        "for feat in available_comparison:\n",
        "    fake_mean = fake_df[feat].mean()\n",
        "    legit_mean = legit_df[feat].mean()\n",
        "    diff = fake_mean - legit_mean\n",
        "    print(f\"   {feat:<30} {fake_mean:<15.2f} {legit_mean:<15.2f} {diff:<15.2f}\")\n",
        "\n",
        "# Wizualizacje\n",
        "print(\"\\n   Generowanie wizualizacji...\")\n",
        "\n",
        "fig = plt.figure(figsize=(18, 12))\n",
        "\n",
        "# 1. Fraud probability distribution\n",
        "ax1 = plt.subplot(3, 3, 1)\n",
        "ax1.hist(df_model3['fraud_probability'], bins=50, edgecolor='black', color='#FF6B6B', alpha=0.7)\n",
        "threshold_95 = df_model3['fraud_probability'].quantile(0.95)\n",
        "ax1.axvline(threshold_95, color='red', linestyle='--', linewidth=2,\n",
        "            label=f'95th percentile: {threshold_95:.1f}%')\n",
        "ax1.set_xlabel('Fraud Probability (%)', fontsize=10)\n",
        "ax1.set_ylabel('Count', fontsize=10)\n",
        "ax1.set_title('Distribution of Fraud Scores', fontsize=12, fontweight='bold')\n",
        "ax1.legend()\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# 2. Anomaly score distribution\n",
        "ax2 = plt.subplot(3, 3, 2)\n",
        "ax2.hist(df_model3['anomaly_score'], bins=50, edgecolor='black', color='#4ECDC4', alpha=0.7)\n",
        "ax2.axvline(0, color='red', linestyle='--', linewidth=2, label='Decision boundary')\n",
        "ax2.set_xlabel('Anomaly Score', fontsize=10)\n",
        "ax2.set_ylabel('Count', fontsize=10)\n",
        "ax2.set_title('Isolation Forest Anomaly Scores', fontsize=12, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "# 3. Fake vs Legit count\n",
        "ax3 = plt.subplot(3, 3, 3)\n",
        "counts = df_model3['is_fake_review'].value_counts()\n",
        "colors = ['#4ECDC4', '#FF6B6B']\n",
        "ax3.bar(['Legit', 'Fake'], [counts.get(0, 0), counts.get(1, 0)], color=colors, edgecolor='black')\n",
        "ax3.set_ylabel('Count', fontsize=10)\n",
        "ax3.set_title('Fake vs Legit Reviews', fontsize=12, fontweight='bold')\n",
        "for i, v in enumerate([counts.get(0, 0), counts.get(1, 0)]):\n",
        "    ax3.text(i, v + 100, f'{v:,}\\n({v/len(df_model3)*100:.1f}%)', ha='center', fontweight='bold')\n",
        "ax3.grid(alpha=0.3, axis='y')\n",
        "\n",
        "# 4. Feature comparison: reviewer_reviews_last_7d\n",
        "if 'reviewer_reviews_last_7d' in df_model3.columns:\n",
        "    ax4 = plt.subplot(3, 3, 4)\n",
        "    ax4.boxplot([legit_df['reviewer_reviews_last_7d'], fake_df['reviewer_reviews_last_7d']],\n",
        "                labels=['Legit', 'Fake'], patch_artist=True)\n",
        "    ax4.set_ylabel('Reviews in 7d', fontsize=10)\n",
        "    ax4.set_title('Burst Activity: Fake vs Legit', fontsize=12, fontweight='bold')\n",
        "    ax4.grid(alpha=0.3, axis='y')\n",
        "\n",
        "# 5. Feature comparison: positive_ratio\n",
        "if 'positive_ratio' in df_model3.columns:\n",
        "    ax5 = plt.subplot(3, 3, 5)\n",
        "    ax5.hist(legit_df['positive_ratio'], bins=30, alpha=0.6, label='Legit', color='#4ECDC4', edgecolor='black')\n",
        "    ax5.hist(fake_df['positive_ratio'], bins=30, alpha=0.6, label='Fake', color='#FF6B6B', edgecolor='black')\n",
        "    ax5.axvline(0.95, color='red', linestyle='--', alpha=0.5)\n",
        "    ax5.axvline(0.05, color='red', linestyle='--', alpha=0.5)\n",
        "    ax5.set_xlabel('Positive Ratio', fontsize=10)\n",
        "    ax5.set_ylabel('Count', fontsize=10)\n",
        "    ax5.set_title('Bias Detection', fontsize=12, fontweight='bold')\n",
        "    ax5.legend()\n",
        "    ax5.grid(alpha=0.3)\n",
        "\n",
        "# 6. Feature comparison: lexical_diversity\n",
        "if 'lexical_diversity' in df_model3.columns:\n",
        "    ax6 = plt.subplot(3, 3, 6)\n",
        "    ax6.hist(legit_df['lexical_diversity'], bins=30, alpha=0.6, label='Legit', color='#4ECDC4', edgecolor='black')\n",
        "    ax6.hist(fake_df['lexical_diversity'], bins=30, alpha=0.6, label='Fake', color='#FF6B6B', edgecolor='black')\n",
        "    ax6.set_xlabel('Lexical Diversity', fontsize=10)\n",
        "    ax6.set_ylabel('Count', fontsize=10)\n",
        "    ax6.set_title('Text Quality', fontsize=12, fontweight='bold')\n",
        "    ax6.legend()\n",
        "    ax6.grid(alpha=0.3)\n",
        "\n",
        "# 7. Scatter: burst vs positive_ratio\n",
        "if 'reviewer_reviews_last_7d' in df_model3.columns and 'positive_ratio' in df_model3.columns:\n",
        "    ax7 = plt.subplot(3, 3, 7)\n",
        "    ax7.scatter(legit_df['reviewer_reviews_last_7d'], legit_df['positive_ratio'],\n",
        "                alpha=0.3, s=10, color='#4ECDC4', label='Legit')\n",
        "    ax7.scatter(fake_df['reviewer_reviews_last_7d'], fake_df['positive_ratio'],\n",
        "                alpha=0.5, s=20, color='#FF6B6B', marker='x', label='Fake')\n",
        "    ax7.set_xlabel('Reviews in 7d', fontsize=10)\n",
        "    ax7.set_ylabel('Positive Ratio', fontsize=10)\n",
        "    ax7.set_title('Multi-dimensional Anomalies', fontsize=12, fontweight='bold')\n",
        "    ax7.legend()\n",
        "    ax7.grid(alpha=0.3)\n",
        "\n",
        "# 8. Feature importance\n",
        "ax8 = plt.subplot(3, 3, 8)\n",
        "feature_names = all_features + [f'text_emb_{i}' for i in range(10)]\n",
        "feature_matrix = pd.DataFrame(combined_features, columns=feature_names)\n",
        "feature_matrix['anomaly_score'] = anomaly_scores\n",
        "correlations = feature_matrix.corr()['anomaly_score'].drop('anomaly_score').abs().sort_values(ascending=False)\n",
        "top_corr = correlations.head(15)\n",
        "ax8.barh(range(len(top_corr)), top_corr.values, color='#45B7D1', edgecolor='black')\n",
        "ax8.set_yticks(range(len(top_corr)))\n",
        "ax8.set_yticklabels(top_corr.index, fontsize=8)\n",
        "ax8.set_xlabel('Abs Correlation', fontsize=10)\n",
        "ax8.set_title('Feature Importance (Proxy)', fontsize=12, fontweight='bold')\n",
        "ax8.invert_yaxis()\n",
        "ax8.grid(alpha=0.3, axis='x')\n",
        "\n",
        "# 9. Fraud probability by days_since_release\n",
        "if 'days_since_release' in df_model3.columns:\n",
        "    ax9 = plt.subplot(3, 3, 9)\n",
        "    bins = [-np.inf, 7, 30, 90, np.inf]\n",
        "    labels = ['<7d', '7-30d', '30-90d', '>90d']\n",
        "    df_model3['release_bin'] = pd.cut(df_model3['days_since_release'], bins=bins, labels=labels)\n",
        "    fraud_by_timing = df_model3.groupby('release_bin')['fraud_probability'].mean()\n",
        "    ax9.bar(range(len(fraud_by_timing)), fraud_by_timing.values, color='#FF6B6B', edgecolor='black')\n",
        "    ax9.set_xticks(range(len(fraud_by_timing)))\n",
        "    ax9.set_xticklabels(fraud_by_timing.index)\n",
        "    ax9.set_ylabel('Avg Fraud Probability (%)', fontsize=10)\n",
        "    ax9.set_title('Fraud Risk by Review Timing', fontsize=12, fontweight='bold')\n",
        "    ax9.grid(alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('model3_fake_review_detection_analysis.png', dpi=150, bbox_inches='tight')\n",
        "print(\"      Zapisano: model3_fake_review_detection_analysis.png\")\n",
        "plt.show()\n",
        "\n",
        "# Zapis wyników\n",
        "print(\"\\n   Zapis wyników...\")\n",
        "\n",
        "output_cols = [\n",
        "    'fraud_probability', 'is_fake_review', 'anomaly_score',\n",
        "    'text_cleaned', 'review_content',\n",
        "    'reviewer_reviews_last_7d', 'positive_ratio', 'days_since_release',\n",
        "    'lexical_diversity', 'score_std', 'suspicious_score',\n",
        "    'movie_title', 'critic_name', 'review_date'\n",
        "]\n",
        "\n",
        "output_cols_available = [col for col in output_cols if col in df_model3.columns]\n",
        "\n",
        "df_model3[output_cols_available].to_csv('model3_all_results.csv', index=False, encoding='utf-8')\n",
        "print(\"      Zapisano: model3_all_results.csv\")\n",
        "\n",
        "top_suspicious[output_cols_available].to_csv('model3_top_suspicious.csv', index=False, encoding='utf-8')\n",
        "print(f\"      Zapisano: model3_top_suspicious.csv (top {top_n})\")\n",
        "\n",
        "with open('model3_summary.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(\"MODEL 3: HYBRID ISOLATION FOREST - PODSUMOWANIE\\n\\n\")\n",
        "    f.write(f\"Łącznie recenzji: {len(df_model3):,}\\n\")\n",
        "    f.write(f\"Oznaczone jako fake: {fake_count:,} ({fake_pct:.2f}%)\\n\")\n",
        "    f.write(f\"Contamination threshold: {contamination*100}%\\n\\n\")\n",
        "    f.write(\"Konfiguracja cech:\\n\")\n",
        "    f.write(f\"  Cechy numeryczne: {len(all_features)}\\n\")\n",
        "    f.write(f\"  Text embedding dims: 10 (UMAP z 384)\\n\")\n",
        "    f.write(f\"  Łączne wymiary: {combined_features.shape[1]}\\n\\n\")\n",
        "    f.write(\"Top cechy wg korelacji z anomaly score:\\n\")\n",
        "    for i, (feat, corr) in enumerate(correlations.head(10).items(), 1):\n",
        "        f.write(f\"  {i}. {feat}: {corr:.3f}\\n\")\n",
        "\n",
        "print(\"      Zapisano: model3_summary.txt\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}